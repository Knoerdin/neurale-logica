{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset ,DataLoader\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input / output format\n",
    "Input is in de vorm van twee vectors die waardes 1 en 0 bevatten (waar of onwaar).\\\n",
    "De waardes van de **eerste** vector moeten worden gelezen alsof er conjuncten tussen staan, een voorbeeld is de vector (0,1) die kan worden gelezen als: niet A en B.\\\n",
    "De waardes van de **tweede** vector moeten worden gelezen alsof er disjuncten tussen staan, verder zijn er altijd exact twee true values in de vector.\\\n",
    "Deze vectoren worden vergeleken (bijvoorbeeld (0,0,1) en (0,1,1) is True) en de output zal true of false zijn.\\\n",
    "De hoeveelheid mogelijke combinaties zijn 2^n * (n!/(2!(n-2)!)), voor n = 3 is dit 24.\\\n",
    "\\\n",
    "Alle combinaties waar de eerste vector gelijk is aan de tweede vector worden verwijderd.\\\n",
    "\\\n",
    "In deze poging ga ik de tien keer regel gebruiken, dit houd in dat voor elk mogelijk input-output paar er tien kopieÃ«ren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(((0, 0, 0), (0, 1, 1)), False), (((0, 0, 0), (1, 0, 1)), False), (((0, 0, 0), (1, 1, 0)), False), (((0, 0, 1), (0, 1, 1)), True), (((0, 0, 1), (1, 0, 1)), True), (((0, 0, 1), (1, 1, 0)), False), (((0, 1, 0), (0, 1, 1)), True), (((0, 1, 0), (1, 0, 1)), False), (((0, 1, 0), (1, 1, 0)), True), (((0, 1, 1), (1, 0, 1)), True), (((0, 1, 1), (1, 1, 0)), True), (((1, 0, 0), (0, 1, 1)), False), (((1, 0, 0), (1, 0, 1)), True), (((1, 0, 0), (1, 1, 0)), True), (((1, 0, 1), (0, 1, 1)), True), (((1, 0, 1), (1, 1, 0)), True), (((1, 1, 0), (0, 1, 1)), True), (((1, 1, 0), (1, 0, 1)), True), (((1, 1, 1), (0, 1, 1)), True), (((1, 1, 1), (1, 0, 1)), True), (((1, 1, 1), (1, 1, 0)), True)]\n"
     ]
    }
   ],
   "source": [
    "#generate input vectors\n",
    "def generate_input_vectors(n):\n",
    "    fist_vec = list(it.product([0, 1], repeat=n))\n",
    "    second_vec = []\n",
    "    for i in fist_vec:\n",
    "        if i.count(1) == 2:\n",
    "            second_vec.append(i)\n",
    "    total_vec = list(it.product(fist_vec, second_vec))\n",
    "    for i in total_vec:\n",
    "        if i[0] == i[1]:\n",
    "            total_vec.remove(i)\n",
    "    return total_vec\n",
    "#generate validation vectors\n",
    "def generate_val(n):\n",
    "    fist_vec = list(it.product([0, 1], repeat=n))\n",
    "    second_vec = []\n",
    "    for i in fist_vec:\n",
    "        if i.count(1) == 2:\n",
    "            second_vec.append(i)\n",
    "    total_vec = list(it.product(fist_vec, second_vec))\n",
    "    return total_vec\n",
    "#generate true output\n",
    "def generate_true(x):\n",
    "    out = []\n",
    "    for pair in x:\n",
    "        for i in range(len(pair[0])):\n",
    "            if pair[0][i] == 1 and pair[1][i] == 1:\n",
    "                out.append(((pair[0],pair[1]),True))\n",
    "                break\n",
    "            elif i == len(pair[0]) - 1:\n",
    "                out.append(((pair[0],pair[1]),False))\n",
    "    return out\n",
    "print(generate_true(generate_input_vectors(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.X = [torch.tensor(i[0]) for i in data]\n",
    "        self.y = torch.tensor([i[1] for i in data], dtype=torch.bool)\n",
    "        self.data = list(zip(self.X, self.y))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size = 7140, Val size = 7168\n"
     ]
    }
   ],
   "source": [
    "formula_size = 8\n",
    "\n",
    "data_train = generate_true(generate_input_vectors(formula_size))\n",
    "dataset_train = CustomDataset(data_train)\n",
    "data_val = generate_true(generate_val(formula_size))\n",
    "dataset_val = CustomDataset(data_val)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=4, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=4, shuffle=True)\n",
    "\n",
    "print(f\"Train size = {len(dataset_train)}, Val size = {len(dataset_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_formula(size):\n",
    "    return torch.randint(0, 2, (size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2*formula_size, formula_size)\n",
    "        self.fc2 = nn.Linear(formula_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 2*formula_size)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "preffered_device = 'cpu'\n",
    "second_option = 'cuda'\n",
    "device = torch.device(preffered_device if torch.cuda.is_available() else second_option)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/100], Loss: 0.6396604776382446\n",
      "Epoch: [2/100], Loss: 0.24635909497737885\n",
      "Epoch: [3/100], Loss: 0.2558428645133972\n",
      "Epoch: [4/100], Loss: 0.16226208209991455\n",
      "Epoch: [5/100], Loss: 0.2666414678096771\n",
      "Epoch: [6/100], Loss: 0.0854591429233551\n",
      "Epoch: [7/100], Loss: 0.14694948494434357\n",
      "Epoch: [8/100], Loss: 0.544245183467865\n",
      "Epoch: [9/100], Loss: 0.031345099210739136\n",
      "Epoch: [10/100], Loss: 0.2094084769487381\n",
      "Epoch: [11/100], Loss: 0.6171999573707581\n",
      "Epoch: [12/100], Loss: 0.21772809326648712\n",
      "Epoch: [13/100], Loss: 0.17381983995437622\n",
      "Epoch: [14/100], Loss: 0.15377914905548096\n",
      "Epoch: [15/100], Loss: 0.005127239972352982\n",
      "Epoch: [16/100], Loss: 0.06553126871585846\n",
      "Epoch: [17/100], Loss: 0.09089258313179016\n",
      "Epoch: [18/100], Loss: 0.020655449479818344\n",
      "Epoch: [19/100], Loss: 0.017074856907129288\n",
      "Epoch: [20/100], Loss: 0.028228051960468292\n",
      "Epoch: [21/100], Loss: 0.0011666702339425683\n",
      "Epoch: [22/100], Loss: 0.04064526408910751\n",
      "Epoch: [23/100], Loss: 0.061320893466472626\n",
      "Epoch: [24/100], Loss: 0.0038384543731808662\n",
      "Epoch: [25/100], Loss: 0.021399736404418945\n",
      "Epoch: [26/100], Loss: 0.06368419528007507\n",
      "Epoch: [27/100], Loss: 0.03847457841038704\n",
      "Epoch: [28/100], Loss: 9.387578757014126e-06\n",
      "Epoch: [29/100], Loss: 0.0019843655172735453\n",
      "Epoch: [30/100], Loss: 0.005136496387422085\n",
      "Epoch: [31/100], Loss: 0.000948763859923929\n",
      "Epoch: [32/100], Loss: 0.016747785732150078\n",
      "Epoch: [33/100], Loss: 0.8203495144844055\n",
      "Epoch: [34/100], Loss: 0.004689756780862808\n",
      "Epoch: [35/100], Loss: 0.2083614319562912\n",
      "Epoch: [36/100], Loss: 0.00034865763154812157\n",
      "Epoch: [37/100], Loss: 0.08613208681344986\n",
      "Epoch: [38/100], Loss: 0.0009300053352490067\n",
      "Epoch: [39/100], Loss: 0.32175445556640625\n",
      "Epoch: [40/100], Loss: 0.015185228548943996\n",
      "Epoch: [41/100], Loss: 0.0038655996322631836\n",
      "Epoch: [42/100], Loss: 3.6297533370088786e-05\n",
      "Epoch: [43/100], Loss: 0.04047849029302597\n",
      "Epoch: [44/100], Loss: 0.01210278831422329\n",
      "Epoch: [45/100], Loss: 0.011914159171283245\n",
      "Epoch: [46/100], Loss: 0.000653187045827508\n",
      "Epoch: [47/100], Loss: 0.30789804458618164\n",
      "Epoch: [48/100], Loss: 2.9802320611338473e-08\n",
      "Epoch: [49/100], Loss: 0.008777436800301075\n",
      "Epoch: [50/100], Loss: 1.2755068382830359e-05\n",
      "Epoch: [51/100], Loss: 0.03819447383284569\n",
      "Epoch: [52/100], Loss: 0.00011875301424879581\n",
      "Epoch: [53/100], Loss: 0.002938748337328434\n",
      "Epoch: [54/100], Loss: 0.016121454536914825\n",
      "Epoch: [55/100], Loss: 0.01735743321478367\n",
      "Epoch: [56/100], Loss: 0.017111634835600853\n",
      "Epoch: [57/100], Loss: 0.017060626298189163\n",
      "Epoch: [58/100], Loss: 0.09091117233037949\n",
      "Epoch: [59/100], Loss: 3.209546412108466e-05\n",
      "Epoch: [60/100], Loss: 7.041775097604841e-05\n",
      "Epoch: [61/100], Loss: 0.010496045462787151\n",
      "Epoch: [62/100], Loss: 0.0005330512067303061\n",
      "Epoch: [63/100], Loss: 0.003490810515359044\n",
      "Epoch: [64/100], Loss: 0.017038749530911446\n",
      "Epoch: [65/100], Loss: 0.006293247453868389\n",
      "Epoch: [66/100], Loss: 5.48360276297899e-06\n",
      "Epoch: [67/100], Loss: 0.004613929428160191\n",
      "Epoch: [68/100], Loss: 0.00017524098802823573\n",
      "Epoch: [69/100], Loss: 0.0004796562425326556\n",
      "Epoch: [70/100], Loss: 0.005745610687881708\n",
      "Epoch: [71/100], Loss: 0.0006341089610941708\n",
      "Epoch: [72/100], Loss: 0.02313629537820816\n",
      "Epoch: [73/100], Loss: 0.0001668088953010738\n",
      "Epoch: [74/100], Loss: 0.002151308348402381\n",
      "Epoch: [75/100], Loss: 1.4305097693068092e-06\n",
      "Epoch: [76/100], Loss: 3.7668734876206145e-05\n",
      "Epoch: [77/100], Loss: 0.0003697633510455489\n",
      "Epoch: [78/100], Loss: 0.0019242641283199191\n",
      "Epoch: [79/100], Loss: 0.0012118312297388911\n",
      "Epoch: [80/100], Loss: 0.0007930411375127733\n",
      "Epoch: [81/100], Loss: 0.00010211327025899664\n",
      "Epoch: [82/100], Loss: 0.004519385751336813\n",
      "Epoch: [83/100], Loss: 8.22706933831796e-05\n",
      "Epoch: [84/100], Loss: 0.006446752697229385\n",
      "Epoch: [85/100], Loss: 0.003199363127350807\n",
      "Epoch: [86/100], Loss: 0.0036613750271499157\n",
      "Epoch: [87/100], Loss: 2.032439806498587e-05\n",
      "Epoch: [88/100], Loss: 0.001003485405817628\n",
      "Epoch: [89/100], Loss: 0.08053410053253174\n",
      "Epoch: [90/100], Loss: 2.9802320611338473e-08\n",
      "Epoch: [91/100], Loss: 1.8059557987726294e-05\n",
      "Epoch: [92/100], Loss: 0.000871211348567158\n",
      "Epoch: [93/100], Loss: 1.2218923757245648e-06\n",
      "Epoch: [94/100], Loss: 0.0006444485625252128\n",
      "Epoch: [95/100], Loss: 3.278254894212296e-07\n",
      "Epoch: [96/100], Loss: 5.867664367542602e-05\n",
      "Epoch: [97/100], Loss: 0.0003665679250843823\n",
      "Epoch: [98/100], Loss: 4.4703443791149766e-07\n",
      "Epoch: [99/100], Loss: 1.4901158351676713e-07\n",
      "Epoch: [100/100], Loss: 0.009595360606908798\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in dataloader_train:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch: [{epoch+1}/{epochs}], Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of trained model: 99.97209821428571%\n",
      "Accuracy of random model: 49.330357142857146%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "wrong_input = []\n",
    "wrong_label = []\n",
    "wrong_output = []\n",
    "# evaluate the trained model\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for inputs, labels in dataloader_val:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        #store the wrong predictions\n",
    "        for i in range(len(predicted)):\n",
    "            if predicted[i] != labels[i]:\n",
    "                wrong_input.append(inputs[i])\n",
    "                wrong_label.append(labels[i])\n",
    "                wrong_output.append(predicted[i])\n",
    "\n",
    "# evaluate the random model\n",
    "random_correct = 0\n",
    "random_total = 0\n",
    "predictions = random_formula(len(dataset_val))\n",
    "for i in range(len(dataloader_val)):\n",
    "    if (predictions[i] == 1 and dataset_val[i][1] == True) or (predictions[i] == 0 and dataset_val[i][1] == False):\n",
    "        random_correct += 1\n",
    "        random_total += 1\n",
    "    else:\n",
    "        random_total += 1\n",
    "\n",
    "print(f'Accuracy of trained model: {100 * correct / total}%')\n",
    "print(f'Accuracy of random model: {100 * random_correct / random_total}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([[1, 1, 1, 1, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 1]]), Label: False, Output: 1\n",
      "Input: tensor([[1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 1]]), Label: False, Output: 1\n"
     ]
    }
   ],
   "source": [
    "# visualize wrong predictions\n",
    "for i in range(len(wrong_input)):\n",
    "    print(f'Input: {wrong_input[i]}, Label: {wrong_label[i]}, Output: {wrong_output[i]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
