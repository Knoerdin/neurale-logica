{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset ,DataLoader\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input / output format\n",
    "Input is in de vorm van twee vectors die waardes 1 en 0 bevatten (waar of onwaar).\\\n",
    "De waardes van de **eerste** vector moeten worden gelezen alsof er conjuncten tussen staan, een voorbeeld is de vector (0,1) die kan worden gelezen als: niet A en B.\\\n",
    "De waardes van de **tweede** vector moeten worden gelezen alsof er disjuncten tussen staan, verder zijn er altijd exact twee true values in de vector.\\\n",
    "Deze vectoren worden vergeleken (bijvoorbeeld (0,0,1) en (0,1,1) is True) en de output zal true of false zijn.\\\n",
    "De hoeveelheid mogelijke combinaties zijn 2^n * (n!/(2!(n-2)!)), voor n = 3 is dit 24.\\\n",
    "\\\n",
    "Alle combinaties waar de eerste vector gelijk is aan de tweede vector worden verwijderd.\\\n",
    "\\\n",
    "In deze poging ga ik de tien keer regel gebruiken, dit houd in dat voor elk mogelijk input-output paar er tien kopieÃ«ren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(((0, 0, 0), (0, 1, 1)), False), (((0, 0, 0), (1, 0, 1)), False), (((0, 0, 0), (1, 1, 0)), False), (((0, 0, 1), (0, 1, 1)), True), (((0, 0, 1), (1, 0, 1)), True), (((0, 0, 1), (1, 1, 0)), False), (((0, 1, 0), (0, 1, 1)), True), (((0, 1, 0), (1, 0, 1)), False), (((0, 1, 0), (1, 1, 0)), True), (((0, 1, 1), (1, 0, 1)), True), (((0, 1, 1), (1, 1, 0)), True), (((1, 0, 0), (0, 1, 1)), False), (((1, 0, 0), (1, 0, 1)), True), (((1, 0, 0), (1, 1, 0)), True), (((1, 0, 1), (0, 1, 1)), True), (((1, 0, 1), (1, 1, 0)), True), (((1, 1, 0), (0, 1, 1)), True), (((1, 1, 0), (1, 0, 1)), True), (((1, 1, 1), (0, 1, 1)), True), (((1, 1, 1), (1, 0, 1)), True), (((1, 1, 1), (1, 1, 0)), True)]\n"
     ]
    }
   ],
   "source": [
    "#generate input vectors\n",
    "def generate_input_vectors(n):\n",
    "    fist_vec = list(it.product([0, 1], repeat=n))\n",
    "    second_vec = []\n",
    "    for i in fist_vec:\n",
    "        if i.count(1) == 2:\n",
    "            second_vec.append(i)\n",
    "    total_vec = list(it.product(fist_vec, second_vec))\n",
    "    for i in total_vec:\n",
    "        if i[0] == i[1]:\n",
    "            total_vec.remove(i)\n",
    "    return total_vec\n",
    "#generate true output\n",
    "def generate_true(x):\n",
    "    out = []\n",
    "    for pair in x:\n",
    "        for i in range(len(pair[0])):\n",
    "            if pair[0][i] == 1 and pair[1][i] == 1:\n",
    "                out.append(((pair[0],pair[1]),True))\n",
    "                break\n",
    "            elif i == len(pair[0]) - 1:\n",
    "                out.append(((pair[0],pair[1]),False))\n",
    "    return out\n",
    "print(generate_true(generate_input_vectors(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.X = [torch.tensor(i[0]) for i in data]\n",
    "        self.y = torch.tensor([i[1] for i in data], dtype=torch.bool)\n",
    "        self.data = list(zip(self.X, self.y))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_true(generate_input_vectors(5))\n",
    "dataset = CustomDataset(data)\n",
    "dataloader_train = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.fc2 = nn.Linear(5, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 10)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model = NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/1000], Loss: 0.9682886600494385\n",
      "Epoch: [2/1000], Loss: 0.5890247821807861\n",
      "Epoch: [3/1000], Loss: 0.3079911768436432\n",
      "Epoch: [4/1000], Loss: 0.3853124678134918\n",
      "Epoch: [5/1000], Loss: 0.5858852863311768\n",
      "Epoch: [6/1000], Loss: 1.4553664922714233\n",
      "Epoch: [7/1000], Loss: 0.21674329042434692\n",
      "Epoch: [8/1000], Loss: 0.6210575103759766\n",
      "Epoch: [9/1000], Loss: 0.22672627866268158\n",
      "Epoch: [10/1000], Loss: 0.373146116733551\n",
      "Epoch: [11/1000], Loss: 0.27023422718048096\n",
      "Epoch: [12/1000], Loss: 0.5716463327407837\n",
      "Epoch: [13/1000], Loss: 0.5531429648399353\n",
      "Epoch: [14/1000], Loss: 0.3617790937423706\n",
      "Epoch: [15/1000], Loss: 0.22530487179756165\n",
      "Epoch: [16/1000], Loss: 0.21910415589809418\n",
      "Epoch: [17/1000], Loss: 0.12658557295799255\n",
      "Epoch: [18/1000], Loss: 0.3367706835269928\n",
      "Epoch: [19/1000], Loss: 0.5948202013969421\n",
      "Epoch: [20/1000], Loss: 0.37487369775772095\n",
      "Epoch: [21/1000], Loss: 0.4346020519733429\n",
      "Epoch: [22/1000], Loss: 1.2564401626586914\n",
      "Epoch: [23/1000], Loss: 0.3031079173088074\n",
      "Epoch: [24/1000], Loss: 0.5537625551223755\n",
      "Epoch: [25/1000], Loss: 0.22973066568374634\n",
      "Epoch: [26/1000], Loss: 0.2746864855289459\n",
      "Epoch: [27/1000], Loss: 0.22121788561344147\n",
      "Epoch: [28/1000], Loss: 0.5509055256843567\n",
      "Epoch: [29/1000], Loss: 1.2377045154571533\n",
      "Epoch: [30/1000], Loss: 0.7530114650726318\n",
      "Epoch: [31/1000], Loss: 0.24058330059051514\n",
      "Epoch: [32/1000], Loss: 0.2796773314476013\n",
      "Epoch: [33/1000], Loss: 1.1041773557662964\n",
      "Epoch: [34/1000], Loss: 0.6729499697685242\n",
      "Epoch: [35/1000], Loss: 0.028742481023073196\n",
      "Epoch: [36/1000], Loss: 0.3036327660083771\n",
      "Epoch: [37/1000], Loss: 0.5414721965789795\n",
      "Epoch: [38/1000], Loss: 0.3692156970500946\n",
      "Epoch: [39/1000], Loss: 0.3819410502910614\n",
      "Epoch: [40/1000], Loss: 0.4059053957462311\n",
      "Epoch: [41/1000], Loss: 0.3685923218727112\n",
      "Epoch: [42/1000], Loss: 0.2020973563194275\n",
      "Epoch: [43/1000], Loss: 0.24089226126670837\n",
      "Epoch: [44/1000], Loss: 0.20139408111572266\n",
      "Epoch: [45/1000], Loss: 0.4854812026023865\n",
      "Epoch: [46/1000], Loss: 0.07749304920434952\n",
      "Epoch: [47/1000], Loss: 0.37576475739479065\n",
      "Epoch: [48/1000], Loss: 0.13398867845535278\n",
      "Epoch: [49/1000], Loss: 0.33184245228767395\n",
      "Epoch: [50/1000], Loss: 0.1736518144607544\n",
      "Epoch: [51/1000], Loss: 0.5764291286468506\n",
      "Epoch: [52/1000], Loss: 0.15108519792556763\n",
      "Epoch: [53/1000], Loss: 0.13897842168807983\n",
      "Epoch: [54/1000], Loss: 0.7095702886581421\n",
      "Epoch: [55/1000], Loss: 1.1868056058883667\n",
      "Epoch: [56/1000], Loss: 0.5047951936721802\n",
      "Epoch: [57/1000], Loss: 0.2899715304374695\n",
      "Epoch: [58/1000], Loss: 0.4203220009803772\n",
      "Epoch: [59/1000], Loss: 0.5146540403366089\n",
      "Epoch: [60/1000], Loss: 0.0527956597507\n",
      "Epoch: [61/1000], Loss: 0.04555373638868332\n",
      "Epoch: [62/1000], Loss: 0.1445491760969162\n",
      "Epoch: [63/1000], Loss: 0.37391453981399536\n",
      "Epoch: [64/1000], Loss: 0.5783226490020752\n",
      "Epoch: [65/1000], Loss: 0.3303963243961334\n",
      "Epoch: [66/1000], Loss: 0.16702228784561157\n",
      "Epoch: [67/1000], Loss: 0.13010163605213165\n",
      "Epoch: [68/1000], Loss: 0.33506718277931213\n",
      "Epoch: [69/1000], Loss: 0.0762505903840065\n",
      "Epoch: [70/1000], Loss: 0.3765237331390381\n",
      "Epoch: [71/1000], Loss: 0.0734935849905014\n",
      "Epoch: [72/1000], Loss: 0.613585352897644\n",
      "Epoch: [73/1000], Loss: 1.0807024240493774\n",
      "Epoch: [74/1000], Loss: 0.07494591176509857\n",
      "Epoch: [75/1000], Loss: 0.10112524032592773\n",
      "Epoch: [76/1000], Loss: 0.11849302053451538\n",
      "Epoch: [77/1000], Loss: 0.034393977373838425\n",
      "Epoch: [78/1000], Loss: 0.03289496898651123\n",
      "Epoch: [79/1000], Loss: 0.0977342277765274\n",
      "Epoch: [80/1000], Loss: 0.08599933236837387\n",
      "Epoch: [81/1000], Loss: 0.08724468946456909\n",
      "Epoch: [82/1000], Loss: 1.0085182189941406\n",
      "Epoch: [83/1000], Loss: 0.62550288438797\n",
      "Epoch: [84/1000], Loss: 0.30831852555274963\n",
      "Epoch: [85/1000], Loss: 0.2435252070426941\n",
      "Epoch: [86/1000], Loss: 0.04831678792834282\n",
      "Epoch: [87/1000], Loss: 0.07409041374921799\n",
      "Epoch: [88/1000], Loss: 0.085243359208107\n",
      "Epoch: [89/1000], Loss: 1.2130472660064697\n",
      "Epoch: [90/1000], Loss: 0.09490326792001724\n",
      "Epoch: [91/1000], Loss: 0.6948107481002808\n",
      "Epoch: [92/1000], Loss: 0.06712103635072708\n",
      "Epoch: [93/1000], Loss: 0.5687837600708008\n",
      "Epoch: [94/1000], Loss: 0.8406659364700317\n",
      "Epoch: [95/1000], Loss: 0.027706919237971306\n",
      "Epoch: [96/1000], Loss: 0.01765616238117218\n",
      "Epoch: [97/1000], Loss: 0.09245264530181885\n",
      "Epoch: [98/1000], Loss: 0.05725149065256119\n",
      "Epoch: [99/1000], Loss: 0.1288442313671112\n",
      "Epoch: [100/1000], Loss: 0.23872219026088715\n",
      "Epoch: [101/1000], Loss: 0.03696988523006439\n",
      "Epoch: [102/1000], Loss: 0.39283108711242676\n",
      "Epoch: [103/1000], Loss: 0.19286012649536133\n",
      "Epoch: [104/1000], Loss: 0.16813887655735016\n",
      "Epoch: [105/1000], Loss: 0.011718821711838245\n",
      "Epoch: [106/1000], Loss: 0.24521347880363464\n",
      "Epoch: [107/1000], Loss: 0.19694814085960388\n",
      "Epoch: [108/1000], Loss: 0.46845564246177673\n",
      "Epoch: [109/1000], Loss: 0.49008727073669434\n",
      "Epoch: [110/1000], Loss: 0.07462123036384583\n",
      "Epoch: [111/1000], Loss: 0.5935413837432861\n",
      "Epoch: [112/1000], Loss: 0.48780661821365356\n",
      "Epoch: [113/1000], Loss: 0.0664462149143219\n",
      "Epoch: [114/1000], Loss: 0.05288010835647583\n",
      "Epoch: [115/1000], Loss: 0.13304023444652557\n",
      "Epoch: [116/1000], Loss: 1.1164249181747437\n",
      "Epoch: [117/1000], Loss: 0.03574831038713455\n",
      "Epoch: [118/1000], Loss: 1.2909510135650635\n",
      "Epoch: [119/1000], Loss: 0.013006284832954407\n",
      "Epoch: [120/1000], Loss: 0.4641261398792267\n",
      "Epoch: [121/1000], Loss: 0.07828247547149658\n",
      "Epoch: [122/1000], Loss: 0.034410566091537476\n",
      "Epoch: [123/1000], Loss: 0.052237361669540405\n",
      "Epoch: [124/1000], Loss: 0.2832372188568115\n",
      "Epoch: [125/1000], Loss: 0.2675909101963043\n",
      "Epoch: [126/1000], Loss: 1.365337610244751\n",
      "Epoch: [127/1000], Loss: 0.8837432265281677\n",
      "Epoch: [128/1000], Loss: 0.018642669543623924\n",
      "Epoch: [129/1000], Loss: 0.5221796035766602\n",
      "Epoch: [130/1000], Loss: 0.3351454436779022\n",
      "Epoch: [131/1000], Loss: 0.33418479561805725\n",
      "Epoch: [132/1000], Loss: 0.41968831419944763\n",
      "Epoch: [133/1000], Loss: 0.5532056093215942\n",
      "Epoch: [134/1000], Loss: 0.197507843375206\n",
      "Epoch: [135/1000], Loss: 0.3105725049972534\n",
      "Epoch: [136/1000], Loss: 0.01323420275002718\n",
      "Epoch: [137/1000], Loss: 0.32253414392471313\n",
      "Epoch: [138/1000], Loss: 0.07619825750589371\n",
      "Epoch: [139/1000], Loss: 0.15901702642440796\n",
      "Epoch: [140/1000], Loss: 0.036179687827825546\n",
      "Epoch: [141/1000], Loss: 0.13033902645111084\n",
      "Epoch: [142/1000], Loss: 0.13550789654254913\n",
      "Epoch: [143/1000], Loss: 0.14172692596912384\n",
      "Epoch: [144/1000], Loss: 0.888810932636261\n",
      "Epoch: [145/1000], Loss: 0.37150877714157104\n",
      "Epoch: [146/1000], Loss: 0.05590451508760452\n",
      "Epoch: [147/1000], Loss: 0.27901506423950195\n",
      "Epoch: [148/1000], Loss: 0.01728251948952675\n",
      "Epoch: [149/1000], Loss: 0.0116953756660223\n",
      "Epoch: [150/1000], Loss: 0.09716374427080154\n",
      "Epoch: [151/1000], Loss: 0.0845852866768837\n",
      "Epoch: [152/1000], Loss: 1.125938057899475\n",
      "Epoch: [153/1000], Loss: 0.05928037315607071\n",
      "Epoch: [154/1000], Loss: 0.30973565578460693\n",
      "Epoch: [155/1000], Loss: 0.10377536714076996\n",
      "Epoch: [156/1000], Loss: 0.10661345720291138\n",
      "Epoch: [157/1000], Loss: 0.3096636235713959\n",
      "Epoch: [158/1000], Loss: 0.8761452436447144\n",
      "Epoch: [159/1000], Loss: 0.07739748060703278\n",
      "Epoch: [160/1000], Loss: 0.030689839273691177\n",
      "Epoch: [161/1000], Loss: 0.48205000162124634\n",
      "Epoch: [162/1000], Loss: 0.12204063683748245\n",
      "Epoch: [163/1000], Loss: 0.1575426161289215\n",
      "Epoch: [164/1000], Loss: 0.20838597416877747\n",
      "Epoch: [165/1000], Loss: 0.04700477793812752\n",
      "Epoch: [166/1000], Loss: 0.9634221792221069\n",
      "Epoch: [167/1000], Loss: 0.17575162649154663\n",
      "Epoch: [168/1000], Loss: 0.279537171125412\n",
      "Epoch: [169/1000], Loss: 0.2653389871120453\n",
      "Epoch: [170/1000], Loss: 0.10949405282735825\n",
      "Epoch: [171/1000], Loss: 0.4566929340362549\n",
      "Epoch: [172/1000], Loss: 0.010769670829176903\n",
      "Epoch: [173/1000], Loss: 0.30551230907440186\n",
      "Epoch: [174/1000], Loss: 0.3563898503780365\n",
      "Epoch: [175/1000], Loss: 0.9230461716651917\n",
      "Epoch: [176/1000], Loss: 0.0543409138917923\n",
      "Epoch: [177/1000], Loss: 0.33961164951324463\n",
      "Epoch: [178/1000], Loss: 0.10308912396430969\n",
      "Epoch: [179/1000], Loss: 0.2112753838300705\n",
      "Epoch: [180/1000], Loss: 0.07953020930290222\n",
      "Epoch: [181/1000], Loss: 0.2403593510389328\n",
      "Epoch: [182/1000], Loss: 0.020568937063217163\n",
      "Epoch: [183/1000], Loss: 0.12837181985378265\n",
      "Epoch: [184/1000], Loss: 0.4868919849395752\n",
      "Epoch: [185/1000], Loss: 0.25577905774116516\n",
      "Epoch: [186/1000], Loss: 0.04913807287812233\n",
      "Epoch: [187/1000], Loss: 0.1630786657333374\n",
      "Epoch: [188/1000], Loss: 0.7393661141395569\n",
      "Epoch: [189/1000], Loss: 0.32677751779556274\n",
      "Epoch: [190/1000], Loss: 0.3848761320114136\n",
      "Epoch: [191/1000], Loss: 0.4017490744590759\n",
      "Epoch: [192/1000], Loss: 0.05054941773414612\n",
      "Epoch: [193/1000], Loss: 0.660266101360321\n",
      "Epoch: [194/1000], Loss: 0.01910373941063881\n",
      "Epoch: [195/1000], Loss: 0.5201758146286011\n",
      "Epoch: [196/1000], Loss: 0.10386008769273758\n",
      "Epoch: [197/1000], Loss: 0.21287330985069275\n",
      "Epoch: [198/1000], Loss: 0.05801640823483467\n",
      "Epoch: [199/1000], Loss: 0.11182855814695358\n",
      "Epoch: [200/1000], Loss: 0.2821418046951294\n",
      "Epoch: [201/1000], Loss: 2.515403985977173\n",
      "Epoch: [202/1000], Loss: 0.03415728732943535\n",
      "Epoch: [203/1000], Loss: 0.33486536145210266\n",
      "Epoch: [204/1000], Loss: 0.3933522403240204\n",
      "Epoch: [205/1000], Loss: 0.1691271960735321\n",
      "Epoch: [206/1000], Loss: 0.3747406601905823\n",
      "Epoch: [207/1000], Loss: 0.7647850513458252\n",
      "Epoch: [208/1000], Loss: 1.2028276920318604\n",
      "Epoch: [209/1000], Loss: 0.3960580825805664\n",
      "Epoch: [210/1000], Loss: 0.3878976106643677\n",
      "Epoch: [211/1000], Loss: 0.4284379184246063\n",
      "Epoch: [212/1000], Loss: 0.8958460092544556\n",
      "Epoch: [213/1000], Loss: 0.4549155831336975\n",
      "Epoch: [214/1000], Loss: 0.787196695804596\n",
      "Epoch: [215/1000], Loss: 0.026553183794021606\n",
      "Epoch: [216/1000], Loss: 0.007790415547788143\n",
      "Epoch: [217/1000], Loss: 0.07551010698080063\n",
      "Epoch: [218/1000], Loss: 0.05381423979997635\n",
      "Epoch: [219/1000], Loss: 0.05048201233148575\n",
      "Epoch: [220/1000], Loss: 0.0863393023610115\n",
      "Epoch: [221/1000], Loss: 0.02931111678481102\n",
      "Epoch: [222/1000], Loss: 1.2369409799575806\n",
      "Epoch: [223/1000], Loss: 0.46747809648513794\n",
      "Epoch: [224/1000], Loss: 0.8227646946907043\n",
      "Epoch: [225/1000], Loss: 0.006052679847925901\n",
      "Epoch: [226/1000], Loss: 0.6734317541122437\n",
      "Epoch: [227/1000], Loss: 0.05605379119515419\n",
      "Epoch: [228/1000], Loss: 0.10918699204921722\n",
      "Epoch: [229/1000], Loss: 0.09499427676200867\n",
      "Epoch: [230/1000], Loss: 0.1051119714975357\n",
      "Epoch: [231/1000], Loss: 0.0625656321644783\n",
      "Epoch: [232/1000], Loss: 0.01595105044543743\n",
      "Epoch: [233/1000], Loss: 0.007971818558871746\n",
      "Epoch: [234/1000], Loss: 0.11449084430932999\n",
      "Epoch: [235/1000], Loss: 0.32981541752815247\n",
      "Epoch: [236/1000], Loss: 0.14297504723072052\n",
      "Epoch: [237/1000], Loss: 1.5037593841552734\n",
      "Epoch: [238/1000], Loss: 0.19967420399188995\n",
      "Epoch: [239/1000], Loss: 0.21264199912548065\n",
      "Epoch: [240/1000], Loss: 0.8236827850341797\n",
      "Epoch: [241/1000], Loss: 0.09642300009727478\n",
      "Epoch: [242/1000], Loss: 0.19158336520195007\n",
      "Epoch: [243/1000], Loss: 0.1839568316936493\n",
      "Epoch: [244/1000], Loss: 0.9895082712173462\n",
      "Epoch: [245/1000], Loss: 1.1224550008773804\n",
      "Epoch: [246/1000], Loss: 0.08458934724330902\n",
      "Epoch: [247/1000], Loss: 1.2839562892913818\n",
      "Epoch: [248/1000], Loss: 0.27754220366477966\n",
      "Epoch: [249/1000], Loss: 0.3630286455154419\n",
      "Epoch: [250/1000], Loss: 0.02598116546869278\n",
      "Epoch: [251/1000], Loss: 0.7790624499320984\n",
      "Epoch: [252/1000], Loss: 0.37640008330345154\n",
      "Epoch: [253/1000], Loss: 0.42969805002212524\n",
      "Epoch: [254/1000], Loss: 0.327261358499527\n",
      "Epoch: [255/1000], Loss: 0.0458376407623291\n",
      "Epoch: [256/1000], Loss: 0.02488480880856514\n",
      "Epoch: [257/1000], Loss: 0.041096147149801254\n",
      "Epoch: [258/1000], Loss: 0.2592354714870453\n",
      "Epoch: [259/1000], Loss: 0.022768985480070114\n",
      "Epoch: [260/1000], Loss: 0.48240724205970764\n",
      "Epoch: [261/1000], Loss: 0.3972543776035309\n",
      "Epoch: [262/1000], Loss: 0.0231277197599411\n",
      "Epoch: [263/1000], Loss: 0.028019363060593605\n",
      "Epoch: [264/1000], Loss: 0.44190657138824463\n",
      "Epoch: [265/1000], Loss: 0.08737289905548096\n",
      "Epoch: [266/1000], Loss: 1.018650770187378\n",
      "Epoch: [267/1000], Loss: 0.0431603379547596\n",
      "Epoch: [268/1000], Loss: 0.1332661211490631\n",
      "Epoch: [269/1000], Loss: 1.2643924951553345\n",
      "Epoch: [270/1000], Loss: 0.2747303545475006\n",
      "Epoch: [271/1000], Loss: 0.0656919777393341\n",
      "Epoch: [272/1000], Loss: 0.15916363894939423\n",
      "Epoch: [273/1000], Loss: 0.02921447344124317\n",
      "Epoch: [274/1000], Loss: 0.022958973422646523\n",
      "Epoch: [275/1000], Loss: 0.09836631268262863\n",
      "Epoch: [276/1000], Loss: 0.022080853581428528\n",
      "Epoch: [277/1000], Loss: 0.5525413751602173\n",
      "Epoch: [278/1000], Loss: 0.2774519920349121\n",
      "Epoch: [279/1000], Loss: 1.330959677696228\n",
      "Epoch: [280/1000], Loss: 0.09431136399507523\n",
      "Epoch: [281/1000], Loss: 0.11324097216129303\n",
      "Epoch: [282/1000], Loss: 0.10587266832590103\n",
      "Epoch: [283/1000], Loss: 0.491977334022522\n",
      "Epoch: [284/1000], Loss: 0.13979944586753845\n",
      "Epoch: [285/1000], Loss: 0.8613780736923218\n",
      "Epoch: [286/1000], Loss: 0.01782882772386074\n",
      "Epoch: [287/1000], Loss: 0.12546658515930176\n",
      "Epoch: [288/1000], Loss: 0.49494436383247375\n",
      "Epoch: [289/1000], Loss: 0.19505372643470764\n",
      "Epoch: [290/1000], Loss: 0.045832276344299316\n",
      "Epoch: [291/1000], Loss: 0.0413074791431427\n",
      "Epoch: [292/1000], Loss: 1.073129415512085\n",
      "Epoch: [293/1000], Loss: 0.5234623551368713\n",
      "Epoch: [294/1000], Loss: 0.057813916355371475\n",
      "Epoch: [295/1000], Loss: 0.09515920281410217\n",
      "Epoch: [296/1000], Loss: 0.18947194516658783\n",
      "Epoch: [297/1000], Loss: 0.42590996623039246\n",
      "Epoch: [298/1000], Loss: 0.5812191963195801\n",
      "Epoch: [299/1000], Loss: 0.3891248404979706\n",
      "Epoch: [300/1000], Loss: 0.4572297930717468\n",
      "Epoch: [301/1000], Loss: 0.5849518179893494\n",
      "Epoch: [302/1000], Loss: 0.021496158093214035\n",
      "Epoch: [303/1000], Loss: 0.1578136682510376\n",
      "Epoch: [304/1000], Loss: 0.024744942784309387\n",
      "Epoch: [305/1000], Loss: 0.27750730514526367\n",
      "Epoch: [306/1000], Loss: 0.013424307107925415\n",
      "Epoch: [307/1000], Loss: 0.0239076130092144\n",
      "Epoch: [308/1000], Loss: 0.01327253133058548\n",
      "Epoch: [309/1000], Loss: 0.44336676597595215\n",
      "Epoch: [310/1000], Loss: 0.18281462788581848\n",
      "Epoch: [311/1000], Loss: 0.21733704209327698\n",
      "Epoch: [312/1000], Loss: 0.1521960198879242\n",
      "Epoch: [313/1000], Loss: 0.055356428027153015\n",
      "Epoch: [314/1000], Loss: 0.15945900976657867\n",
      "Epoch: [315/1000], Loss: 0.10355440527200699\n",
      "Epoch: [316/1000], Loss: 0.2001306265592575\n",
      "Epoch: [317/1000], Loss: 0.8830410242080688\n",
      "Epoch: [318/1000], Loss: 0.09753607213497162\n",
      "Epoch: [319/1000], Loss: 0.052515462040901184\n",
      "Epoch: [320/1000], Loss: 0.04333654046058655\n",
      "Epoch: [321/1000], Loss: 0.314573734998703\n",
      "Epoch: [322/1000], Loss: 0.17692556977272034\n",
      "Epoch: [323/1000], Loss: 0.2356637865304947\n",
      "Epoch: [324/1000], Loss: 0.1557694524526596\n",
      "Epoch: [325/1000], Loss: 0.05516890436410904\n",
      "Epoch: [326/1000], Loss: 0.652834951877594\n",
      "Epoch: [327/1000], Loss: 0.16469627618789673\n",
      "Epoch: [328/1000], Loss: 0.22018125653266907\n",
      "Epoch: [329/1000], Loss: 0.028204279020428658\n",
      "Epoch: [330/1000], Loss: 0.0029797193128615618\n",
      "Epoch: [331/1000], Loss: 0.42070263624191284\n",
      "Epoch: [332/1000], Loss: 0.08461058884859085\n",
      "Epoch: [333/1000], Loss: 0.4814046025276184\n",
      "Epoch: [334/1000], Loss: 0.7288931608200073\n",
      "Epoch: [335/1000], Loss: 0.27861565351486206\n",
      "Epoch: [336/1000], Loss: 0.14477792382240295\n",
      "Epoch: [337/1000], Loss: 0.16977037489414215\n",
      "Epoch: [338/1000], Loss: 0.06379225850105286\n",
      "Epoch: [339/1000], Loss: 0.20393529534339905\n",
      "Epoch: [340/1000], Loss: 0.1786767691373825\n",
      "Epoch: [341/1000], Loss: 0.40890398621559143\n",
      "Epoch: [342/1000], Loss: 0.8109195232391357\n",
      "Epoch: [343/1000], Loss: 0.24381884932518005\n",
      "Epoch: [344/1000], Loss: 0.00190506293438375\n",
      "Epoch: [345/1000], Loss: 0.027392245829105377\n",
      "Epoch: [346/1000], Loss: 0.3787992596626282\n",
      "Epoch: [347/1000], Loss: 0.054742202162742615\n",
      "Epoch: [348/1000], Loss: 0.0019040154293179512\n",
      "Epoch: [349/1000], Loss: 0.5135514140129089\n",
      "Epoch: [350/1000], Loss: 0.619110643863678\n",
      "Epoch: [351/1000], Loss: 0.20295633375644684\n",
      "Epoch: [352/1000], Loss: 0.37062832713127136\n",
      "Epoch: [353/1000], Loss: 0.27694082260131836\n",
      "Epoch: [354/1000], Loss: 0.0091601787135005\n",
      "Epoch: [355/1000], Loss: 0.3712560832500458\n",
      "Epoch: [356/1000], Loss: 0.11301767081022263\n",
      "Epoch: [357/1000], Loss: 0.6839912533760071\n",
      "Epoch: [358/1000], Loss: 0.4728846549987793\n",
      "Epoch: [359/1000], Loss: 0.19419164955615997\n",
      "Epoch: [360/1000], Loss: 0.058635443449020386\n",
      "Epoch: [361/1000], Loss: 1.262649655342102\n",
      "Epoch: [362/1000], Loss: 0.34152135252952576\n",
      "Epoch: [363/1000], Loss: 0.2024199366569519\n",
      "Epoch: [364/1000], Loss: 0.6496402621269226\n",
      "Epoch: [365/1000], Loss: 0.15510332584381104\n",
      "Epoch: [366/1000], Loss: 0.014028889127075672\n",
      "Epoch: [367/1000], Loss: 0.0031662778928875923\n",
      "Epoch: [368/1000], Loss: 1.1435246467590332\n",
      "Epoch: [369/1000], Loss: 0.5816657543182373\n",
      "Epoch: [370/1000], Loss: 0.6116329431533813\n",
      "Epoch: [371/1000], Loss: 0.05129575356841087\n",
      "Epoch: [372/1000], Loss: 0.10910771787166595\n",
      "Epoch: [373/1000], Loss: 0.13187243044376373\n",
      "Epoch: [374/1000], Loss: 0.32493653893470764\n",
      "Epoch: [375/1000], Loss: 0.040789540857076645\n",
      "Epoch: [376/1000], Loss: 0.268973708152771\n",
      "Epoch: [377/1000], Loss: 0.018788747489452362\n",
      "Epoch: [378/1000], Loss: 0.08133892714977264\n",
      "Epoch: [379/1000], Loss: 0.2905387282371521\n",
      "Epoch: [380/1000], Loss: 0.06922397017478943\n",
      "Epoch: [381/1000], Loss: 1.0796079635620117\n",
      "Epoch: [382/1000], Loss: 0.8722050189971924\n",
      "Epoch: [383/1000], Loss: 0.675794780254364\n",
      "Epoch: [384/1000], Loss: 0.03237456455826759\n",
      "Epoch: [385/1000], Loss: 0.20225754380226135\n",
      "Epoch: [386/1000], Loss: 0.13756921887397766\n",
      "Epoch: [387/1000], Loss: 0.32620495557785034\n",
      "Epoch: [388/1000], Loss: 0.0484871044754982\n",
      "Epoch: [389/1000], Loss: 0.0077914223074913025\n",
      "Epoch: [390/1000], Loss: 0.013334259390830994\n",
      "Epoch: [391/1000], Loss: 0.2182593047618866\n",
      "Epoch: [392/1000], Loss: 0.12720252573490143\n",
      "Epoch: [393/1000], Loss: 0.1707262545824051\n",
      "Epoch: [394/1000], Loss: 0.2029111087322235\n",
      "Epoch: [395/1000], Loss: 0.016723768785595894\n",
      "Epoch: [396/1000], Loss: 0.05094820261001587\n",
      "Epoch: [397/1000], Loss: 1.2260816097259521\n",
      "Epoch: [398/1000], Loss: 0.12337017804384232\n",
      "Epoch: [399/1000], Loss: 0.02758503332734108\n",
      "Epoch: [400/1000], Loss: 0.5062544941902161\n",
      "Epoch: [401/1000], Loss: 0.7562869191169739\n",
      "Epoch: [402/1000], Loss: 0.289055734872818\n",
      "Epoch: [403/1000], Loss: 0.24724777042865753\n",
      "Epoch: [404/1000], Loss: 0.9486835598945618\n",
      "Epoch: [405/1000], Loss: 0.186811625957489\n",
      "Epoch: [406/1000], Loss: 0.005385409574955702\n",
      "Epoch: [407/1000], Loss: 0.11948172748088837\n",
      "Epoch: [408/1000], Loss: 0.005069897510111332\n",
      "Epoch: [409/1000], Loss: 0.018822824582457542\n",
      "Epoch: [410/1000], Loss: 0.14186419546604156\n",
      "Epoch: [411/1000], Loss: 0.5140451192855835\n",
      "Epoch: [412/1000], Loss: 0.12091810256242752\n",
      "Epoch: [413/1000], Loss: 0.017813025042414665\n",
      "Epoch: [414/1000], Loss: 0.009672376327216625\n",
      "Epoch: [415/1000], Loss: 0.33279919624328613\n",
      "Epoch: [416/1000], Loss: 0.4377727508544922\n",
      "Epoch: [417/1000], Loss: 0.48041874170303345\n",
      "Epoch: [418/1000], Loss: 0.10172107070684433\n",
      "Epoch: [419/1000], Loss: 0.10400722920894623\n",
      "Epoch: [420/1000], Loss: 0.026582220569252968\n",
      "Epoch: [421/1000], Loss: 0.06776418536901474\n",
      "Epoch: [422/1000], Loss: 0.06793494522571564\n",
      "Epoch: [423/1000], Loss: 1.0971523523330688\n",
      "Epoch: [424/1000], Loss: 0.4306457042694092\n",
      "Epoch: [425/1000], Loss: 0.223883718252182\n",
      "Epoch: [426/1000], Loss: 0.00791330449283123\n",
      "Epoch: [427/1000], Loss: 0.16706840693950653\n",
      "Epoch: [428/1000], Loss: 0.40917232632637024\n",
      "Epoch: [429/1000], Loss: 0.06866171956062317\n",
      "Epoch: [430/1000], Loss: 0.2734914720058441\n",
      "Epoch: [431/1000], Loss: 0.4703006446361542\n",
      "Epoch: [432/1000], Loss: 0.5403293967247009\n",
      "Epoch: [433/1000], Loss: 0.05850490182638168\n",
      "Epoch: [434/1000], Loss: 0.3123227655887604\n",
      "Epoch: [435/1000], Loss: 0.21531707048416138\n",
      "Epoch: [436/1000], Loss: 0.17119908332824707\n",
      "Epoch: [437/1000], Loss: 0.7481170892715454\n",
      "Epoch: [438/1000], Loss: 0.7178338170051575\n",
      "Epoch: [439/1000], Loss: 0.01180325634777546\n",
      "Epoch: [440/1000], Loss: 0.053070954978466034\n",
      "Epoch: [441/1000], Loss: 0.24162571132183075\n",
      "Epoch: [442/1000], Loss: 0.13629953563213348\n",
      "Epoch: [443/1000], Loss: 1.029826283454895\n",
      "Epoch: [444/1000], Loss: 1.1345893144607544\n",
      "Epoch: [445/1000], Loss: 0.012955920770764351\n",
      "Epoch: [446/1000], Loss: 0.41137614846229553\n",
      "Epoch: [447/1000], Loss: 0.006470144260674715\n",
      "Epoch: [448/1000], Loss: 0.6677528023719788\n",
      "Epoch: [449/1000], Loss: 0.1669781506061554\n",
      "Epoch: [450/1000], Loss: 1.0074462890625\n",
      "Epoch: [451/1000], Loss: 0.020683653652668\n",
      "Epoch: [452/1000], Loss: 0.04834495112299919\n",
      "Epoch: [453/1000], Loss: 0.03771408274769783\n",
      "Epoch: [454/1000], Loss: 0.8111833930015564\n",
      "Epoch: [455/1000], Loss: 0.4566640555858612\n",
      "Epoch: [456/1000], Loss: 0.22254543006420135\n",
      "Epoch: [457/1000], Loss: 0.017064712941646576\n",
      "Epoch: [458/1000], Loss: 0.019587581977248192\n",
      "Epoch: [459/1000], Loss: 0.20205333828926086\n",
      "Epoch: [460/1000], Loss: 0.1338891088962555\n",
      "Epoch: [461/1000], Loss: 0.004688603337854147\n",
      "Epoch: [462/1000], Loss: 0.7131811380386353\n",
      "Epoch: [463/1000], Loss: 0.0076753986068069935\n",
      "Epoch: [464/1000], Loss: 0.7894903421401978\n",
      "Epoch: [465/1000], Loss: 1.343503713607788\n",
      "Epoch: [466/1000], Loss: 0.14781031012535095\n",
      "Epoch: [467/1000], Loss: 0.9541536569595337\n",
      "Epoch: [468/1000], Loss: 0.3818860352039337\n",
      "Epoch: [469/1000], Loss: 0.008991071954369545\n",
      "Epoch: [470/1000], Loss: 0.8544376492500305\n",
      "Epoch: [471/1000], Loss: 0.814487636089325\n",
      "Epoch: [472/1000], Loss: 0.09821990132331848\n",
      "Epoch: [473/1000], Loss: 0.45150870084762573\n",
      "Epoch: [474/1000], Loss: 0.7872342467308044\n",
      "Epoch: [475/1000], Loss: 0.3848607540130615\n",
      "Epoch: [476/1000], Loss: 0.1219472587108612\n",
      "Epoch: [477/1000], Loss: 0.0008587468764744699\n",
      "Epoch: [478/1000], Loss: 0.005643479060381651\n",
      "Epoch: [479/1000], Loss: 0.009402893483638763\n",
      "Epoch: [480/1000], Loss: 0.22300687432289124\n",
      "Epoch: [481/1000], Loss: 0.18237657845020294\n",
      "Epoch: [482/1000], Loss: 0.4295768141746521\n",
      "Epoch: [483/1000], Loss: 0.07623755186796188\n",
      "Epoch: [484/1000], Loss: 0.037175241857767105\n",
      "Epoch: [485/1000], Loss: 0.8541167974472046\n",
      "Epoch: [486/1000], Loss: 0.20673991739749908\n",
      "Epoch: [487/1000], Loss: 0.5011842250823975\n",
      "Epoch: [488/1000], Loss: 0.3440888524055481\n",
      "Epoch: [489/1000], Loss: 0.026414070278406143\n",
      "Epoch: [490/1000], Loss: 0.7171456217765808\n",
      "Epoch: [491/1000], Loss: 0.6335130333900452\n",
      "Epoch: [492/1000], Loss: 0.14930948615074158\n",
      "Epoch: [493/1000], Loss: 0.07550381124019623\n",
      "Epoch: [494/1000], Loss: 0.01052247267216444\n",
      "Epoch: [495/1000], Loss: 0.17284192144870758\n",
      "Epoch: [496/1000], Loss: 0.158197820186615\n",
      "Epoch: [497/1000], Loss: 0.7037850618362427\n",
      "Epoch: [498/1000], Loss: 0.2771620750427246\n",
      "Epoch: [499/1000], Loss: 0.7379348874092102\n",
      "Epoch: [500/1000], Loss: 0.026016702875494957\n",
      "Epoch: [501/1000], Loss: 0.15167935192584991\n",
      "Epoch: [502/1000], Loss: 0.242288738489151\n",
      "Epoch: [503/1000], Loss: 0.01911264844238758\n",
      "Epoch: [504/1000], Loss: 0.06913770735263824\n",
      "Epoch: [505/1000], Loss: 0.12215717136859894\n",
      "Epoch: [506/1000], Loss: 0.05152653157711029\n",
      "Epoch: [507/1000], Loss: 0.1982773095369339\n",
      "Epoch: [508/1000], Loss: 0.19890913367271423\n",
      "Epoch: [509/1000], Loss: 0.01217753067612648\n",
      "Epoch: [510/1000], Loss: 0.07142195850610733\n",
      "Epoch: [511/1000], Loss: 0.5985046625137329\n",
      "Epoch: [512/1000], Loss: 0.41861727833747864\n",
      "Epoch: [513/1000], Loss: 0.02199159376323223\n",
      "Epoch: [514/1000], Loss: 0.0044302986934781075\n",
      "Epoch: [515/1000], Loss: 0.048869356513023376\n",
      "Epoch: [516/1000], Loss: 0.0034624217078089714\n",
      "Epoch: [517/1000], Loss: 0.005746082402765751\n",
      "Epoch: [518/1000], Loss: 0.5137624144554138\n",
      "Epoch: [519/1000], Loss: 0.0009659185307100415\n",
      "Epoch: [520/1000], Loss: 0.17848066985607147\n",
      "Epoch: [521/1000], Loss: 0.03889479115605354\n",
      "Epoch: [522/1000], Loss: 0.1256805956363678\n",
      "Epoch: [523/1000], Loss: 0.46440640091896057\n",
      "Epoch: [524/1000], Loss: 0.8291869163513184\n",
      "Epoch: [525/1000], Loss: 0.3547486960887909\n",
      "Epoch: [526/1000], Loss: 0.30534470081329346\n",
      "Epoch: [527/1000], Loss: 0.015772845596075058\n",
      "Epoch: [528/1000], Loss: 0.09325256198644638\n",
      "Epoch: [529/1000], Loss: 0.39493992924690247\n",
      "Epoch: [530/1000], Loss: 0.20546777546405792\n",
      "Epoch: [531/1000], Loss: 0.08351334929466248\n",
      "Epoch: [532/1000], Loss: 0.0839911624789238\n",
      "Epoch: [533/1000], Loss: 0.2131258100271225\n",
      "Epoch: [534/1000], Loss: 0.15623979270458221\n",
      "Epoch: [535/1000], Loss: 0.10969658941030502\n",
      "Epoch: [536/1000], Loss: 0.6367266774177551\n",
      "Epoch: [537/1000], Loss: 0.13756807148456573\n",
      "Epoch: [538/1000], Loss: 0.01846759393811226\n",
      "Epoch: [539/1000], Loss: 0.33930373191833496\n",
      "Epoch: [540/1000], Loss: 0.009451134130358696\n",
      "Epoch: [541/1000], Loss: 0.08501964062452316\n",
      "Epoch: [542/1000], Loss: 0.0021331191528588533\n",
      "Epoch: [543/1000], Loss: 0.006890690419822931\n",
      "Epoch: [544/1000], Loss: 0.1483210027217865\n",
      "Epoch: [545/1000], Loss: 0.12782281637191772\n",
      "Epoch: [546/1000], Loss: 0.04857325926423073\n",
      "Epoch: [547/1000], Loss: 0.7115696668624878\n",
      "Epoch: [548/1000], Loss: 0.06056477501988411\n",
      "Epoch: [549/1000], Loss: 0.9070165157318115\n",
      "Epoch: [550/1000], Loss: 0.0316401943564415\n",
      "Epoch: [551/1000], Loss: 0.2822076976299286\n",
      "Epoch: [552/1000], Loss: 0.15857014060020447\n",
      "Epoch: [553/1000], Loss: 0.10821975767612457\n",
      "Epoch: [554/1000], Loss: 0.31998056173324585\n",
      "Epoch: [555/1000], Loss: 0.008894247934222221\n",
      "Epoch: [556/1000], Loss: 0.027307434007525444\n",
      "Epoch: [557/1000], Loss: 0.7212467193603516\n",
      "Epoch: [558/1000], Loss: 0.015437974594533443\n",
      "Epoch: [559/1000], Loss: 0.49597328901290894\n",
      "Epoch: [560/1000], Loss: 0.12242420762777328\n",
      "Epoch: [561/1000], Loss: 0.6560431718826294\n",
      "Epoch: [562/1000], Loss: 0.8861227035522461\n",
      "Epoch: [563/1000], Loss: 0.8872709274291992\n",
      "Epoch: [564/1000], Loss: 0.017058072611689568\n",
      "Epoch: [565/1000], Loss: 0.16512291133403778\n",
      "Epoch: [566/1000], Loss: 0.9567239284515381\n",
      "Epoch: [567/1000], Loss: 0.10310481488704681\n",
      "Epoch: [568/1000], Loss: 0.5464287996292114\n",
      "Epoch: [569/1000], Loss: 0.8525676131248474\n",
      "Epoch: [570/1000], Loss: 0.04296192154288292\n",
      "Epoch: [571/1000], Loss: 0.0003118620370514691\n",
      "Epoch: [572/1000], Loss: 0.003824650077149272\n",
      "Epoch: [573/1000], Loss: 0.04313046857714653\n",
      "Epoch: [574/1000], Loss: 0.015742242336273193\n",
      "Epoch: [575/1000], Loss: 0.019785406067967415\n",
      "Epoch: [576/1000], Loss: 0.008132793009281158\n",
      "Epoch: [577/1000], Loss: 0.09886498004198074\n",
      "Epoch: [578/1000], Loss: 0.06778047978878021\n",
      "Epoch: [579/1000], Loss: 0.14462688565254211\n",
      "Epoch: [580/1000], Loss: 0.09791043400764465\n",
      "Epoch: [581/1000], Loss: 0.47003230452537537\n",
      "Epoch: [582/1000], Loss: 0.017707588151097298\n",
      "Epoch: [583/1000], Loss: 0.009745175018906593\n",
      "Epoch: [584/1000], Loss: 0.21767248213291168\n",
      "Epoch: [585/1000], Loss: 0.019285187125205994\n",
      "Epoch: [586/1000], Loss: 0.08283806592226028\n",
      "Epoch: [587/1000], Loss: 0.49803078174591064\n",
      "Epoch: [588/1000], Loss: 0.7148128747940063\n",
      "Epoch: [589/1000], Loss: 0.15473809838294983\n",
      "Epoch: [590/1000], Loss: 0.003331058658659458\n",
      "Epoch: [591/1000], Loss: 0.03536983206868172\n",
      "Epoch: [592/1000], Loss: 0.08366763591766357\n",
      "Epoch: [593/1000], Loss: 0.04102315008640289\n",
      "Epoch: [594/1000], Loss: 0.1824198216199875\n",
      "Epoch: [595/1000], Loss: 0.16530701518058777\n",
      "Epoch: [596/1000], Loss: 0.5170238018035889\n",
      "Epoch: [597/1000], Loss: 0.0023279660381376743\n",
      "Epoch: [598/1000], Loss: 0.0025916676968336105\n",
      "Epoch: [599/1000], Loss: 0.02574295364320278\n",
      "Epoch: [600/1000], Loss: 0.14602208137512207\n",
      "Epoch: [601/1000], Loss: 0.014583844691514969\n",
      "Epoch: [602/1000], Loss: 0.04249086603522301\n",
      "Epoch: [603/1000], Loss: 0.07271159440279007\n",
      "Epoch: [604/1000], Loss: 0.19044899940490723\n",
      "Epoch: [605/1000], Loss: 0.4289773106575012\n",
      "Epoch: [606/1000], Loss: 0.23391595482826233\n",
      "Epoch: [607/1000], Loss: 0.2724688947200775\n",
      "Epoch: [608/1000], Loss: 0.49201491475105286\n",
      "Epoch: [609/1000], Loss: 0.03234308958053589\n",
      "Epoch: [610/1000], Loss: 0.10714509338140488\n",
      "Epoch: [611/1000], Loss: 0.0007989695877768099\n",
      "Epoch: [612/1000], Loss: 0.1877175271511078\n",
      "Epoch: [613/1000], Loss: 0.3928747773170471\n",
      "Epoch: [614/1000], Loss: 0.12145789712667465\n",
      "Epoch: [615/1000], Loss: 0.007233911193907261\n",
      "Epoch: [616/1000], Loss: 0.7829468250274658\n",
      "Epoch: [617/1000], Loss: 0.41858065128326416\n",
      "Epoch: [618/1000], Loss: 0.015032747760415077\n",
      "Epoch: [619/1000], Loss: 0.062457796186208725\n",
      "Epoch: [620/1000], Loss: 0.08297332376241684\n",
      "Epoch: [621/1000], Loss: 0.12942582368850708\n",
      "Epoch: [622/1000], Loss: 0.09326805174350739\n",
      "Epoch: [623/1000], Loss: 0.13036252558231354\n",
      "Epoch: [624/1000], Loss: 0.035480402410030365\n",
      "Epoch: [625/1000], Loss: 0.034362368285655975\n",
      "Epoch: [626/1000], Loss: 0.07346375286579132\n",
      "Epoch: [627/1000], Loss: 0.16500866413116455\n",
      "Epoch: [628/1000], Loss: 0.1321323961019516\n",
      "Epoch: [629/1000], Loss: 0.0705232247710228\n",
      "Epoch: [630/1000], Loss: 0.9879560470581055\n",
      "Epoch: [631/1000], Loss: 0.14396554231643677\n",
      "Epoch: [632/1000], Loss: 0.17773191630840302\n",
      "Epoch: [633/1000], Loss: 0.023814532905817032\n",
      "Epoch: [634/1000], Loss: 0.08684629201889038\n",
      "Epoch: [635/1000], Loss: 8.934054494602606e-05\n",
      "Epoch: [636/1000], Loss: 0.3749454915523529\n",
      "Epoch: [637/1000], Loss: 0.13358572125434875\n",
      "Epoch: [638/1000], Loss: 0.004963161423802376\n",
      "Epoch: [639/1000], Loss: 0.8782336115837097\n",
      "Epoch: [640/1000], Loss: 0.4786490201950073\n",
      "Epoch: [641/1000], Loss: 0.2567277252674103\n",
      "Epoch: [642/1000], Loss: 0.015793433412909508\n",
      "Epoch: [643/1000], Loss: 0.0048655555583536625\n",
      "Epoch: [644/1000], Loss: 0.131332665681839\n",
      "Epoch: [645/1000], Loss: 0.02325030416250229\n",
      "Epoch: [646/1000], Loss: 0.04687820002436638\n",
      "Epoch: [647/1000], Loss: 0.10288575291633606\n",
      "Epoch: [648/1000], Loss: 0.027099285274744034\n",
      "Epoch: [649/1000], Loss: 0.35649994015693665\n",
      "Epoch: [650/1000], Loss: 0.0021800105459988117\n",
      "Epoch: [651/1000], Loss: 0.22216984629631042\n",
      "Epoch: [652/1000], Loss: 0.012466072104871273\n",
      "Epoch: [653/1000], Loss: 0.397947758436203\n",
      "Epoch: [654/1000], Loss: 0.1463344544172287\n",
      "Epoch: [655/1000], Loss: 0.5896075367927551\n",
      "Epoch: [656/1000], Loss: 0.0881468877196312\n",
      "Epoch: [657/1000], Loss: 0.1235651969909668\n",
      "Epoch: [658/1000], Loss: 0.05695080757141113\n",
      "Epoch: [659/1000], Loss: 0.46500226855278015\n",
      "Epoch: [660/1000], Loss: 0.0031496945302933455\n",
      "Epoch: [661/1000], Loss: 0.12653334438800812\n",
      "Epoch: [662/1000], Loss: 0.0011637225979939103\n",
      "Epoch: [663/1000], Loss: 0.11784062534570694\n",
      "Epoch: [664/1000], Loss: 0.8580572605133057\n",
      "Epoch: [665/1000], Loss: 0.19342660903930664\n",
      "Epoch: [666/1000], Loss: 0.21493780612945557\n",
      "Epoch: [667/1000], Loss: 0.5183480381965637\n",
      "Epoch: [668/1000], Loss: 0.16919907927513123\n",
      "Epoch: [669/1000], Loss: 0.07645450532436371\n",
      "Epoch: [670/1000], Loss: 0.009824980050325394\n",
      "Epoch: [671/1000], Loss: 0.09284529834985733\n",
      "Epoch: [672/1000], Loss: 0.21481448411941528\n",
      "Epoch: [673/1000], Loss: 0.06248248368501663\n",
      "Epoch: [674/1000], Loss: 0.0012452409137040377\n",
      "Epoch: [675/1000], Loss: 0.001949293538928032\n",
      "Epoch: [676/1000], Loss: 0.21227827668190002\n",
      "Epoch: [677/1000], Loss: 0.03508680686354637\n",
      "Epoch: [678/1000], Loss: 0.039820022881031036\n",
      "Epoch: [679/1000], Loss: 0.4695955812931061\n",
      "Epoch: [680/1000], Loss: 0.029523493722081184\n",
      "Epoch: [681/1000], Loss: 0.03453493118286133\n",
      "Epoch: [682/1000], Loss: 0.3648359477519989\n",
      "Epoch: [683/1000], Loss: 0.25471168756484985\n",
      "Epoch: [684/1000], Loss: 0.03212180361151695\n",
      "Epoch: [685/1000], Loss: 0.00774187920615077\n",
      "Epoch: [686/1000], Loss: 0.7671422958374023\n",
      "Epoch: [687/1000], Loss: 0.07130234688520432\n",
      "Epoch: [688/1000], Loss: 0.005616681184619665\n",
      "Epoch: [689/1000], Loss: 0.11970624327659607\n",
      "Epoch: [690/1000], Loss: 0.4218320846557617\n",
      "Epoch: [691/1000], Loss: 1.4510152339935303\n",
      "Epoch: [692/1000], Loss: 0.593356192111969\n",
      "Epoch: [693/1000], Loss: 0.021345626562833786\n",
      "Epoch: [694/1000], Loss: 0.10099777579307556\n",
      "Epoch: [695/1000], Loss: 0.003975887317210436\n",
      "Epoch: [696/1000], Loss: 0.36715033650398254\n",
      "Epoch: [697/1000], Loss: 1.1173720359802246\n",
      "Epoch: [698/1000], Loss: 0.09320833534002304\n",
      "Epoch: [699/1000], Loss: 0.045244891196489334\n",
      "Epoch: [700/1000], Loss: 0.7946956157684326\n",
      "Epoch: [701/1000], Loss: 0.07885337620973587\n",
      "Epoch: [702/1000], Loss: 0.43557658791542053\n",
      "Epoch: [703/1000], Loss: 0.9198719263076782\n",
      "Epoch: [704/1000], Loss: 0.0006505975616164505\n",
      "Epoch: [705/1000], Loss: 0.43410569429397583\n",
      "Epoch: [706/1000], Loss: 0.5066421627998352\n",
      "Epoch: [707/1000], Loss: 0.03092736192047596\n",
      "Epoch: [708/1000], Loss: 0.5391998291015625\n",
      "Epoch: [709/1000], Loss: 0.018123282119631767\n",
      "Epoch: [710/1000], Loss: 0.10238231718540192\n",
      "Epoch: [711/1000], Loss: 0.02951008640229702\n",
      "Epoch: [712/1000], Loss: 0.036836426705121994\n",
      "Epoch: [713/1000], Loss: 0.12749995291233063\n",
      "Epoch: [714/1000], Loss: 0.05138272047042847\n",
      "Epoch: [715/1000], Loss: 0.6818444728851318\n",
      "Epoch: [716/1000], Loss: 0.0049803671427071095\n",
      "Epoch: [717/1000], Loss: 0.3687407374382019\n",
      "Epoch: [718/1000], Loss: 0.5521633625030518\n",
      "Epoch: [719/1000], Loss: 0.1230892464518547\n",
      "Epoch: [720/1000], Loss: 0.09592090547084808\n",
      "Epoch: [721/1000], Loss: 0.15116839110851288\n",
      "Epoch: [722/1000], Loss: 0.014786836691200733\n",
      "Epoch: [723/1000], Loss: 0.8923639059066772\n",
      "Epoch: [724/1000], Loss: 0.08998537808656693\n",
      "Epoch: [725/1000], Loss: 0.0523795410990715\n",
      "Epoch: [726/1000], Loss: 0.14672307670116425\n",
      "Epoch: [727/1000], Loss: 0.6228700876235962\n",
      "Epoch: [728/1000], Loss: 0.02088538557291031\n",
      "Epoch: [729/1000], Loss: 0.0075592948123812675\n",
      "Epoch: [730/1000], Loss: 0.47305113077163696\n",
      "Epoch: [731/1000], Loss: 0.01371285505592823\n",
      "Epoch: [732/1000], Loss: 0.5415544509887695\n",
      "Epoch: [733/1000], Loss: 0.022464076057076454\n",
      "Epoch: [734/1000], Loss: 0.07604290544986725\n",
      "Epoch: [735/1000], Loss: 0.16894064843654633\n",
      "Epoch: [736/1000], Loss: 0.028931299224495888\n",
      "Epoch: [737/1000], Loss: 0.14012716710567474\n",
      "Epoch: [738/1000], Loss: 0.15936899185180664\n",
      "Epoch: [739/1000], Loss: 0.04330642148852348\n",
      "Epoch: [740/1000], Loss: 0.0003762826672755182\n",
      "Epoch: [741/1000], Loss: 0.1089024469256401\n",
      "Epoch: [742/1000], Loss: 0.915422260761261\n",
      "Epoch: [743/1000], Loss: 0.42327362298965454\n",
      "Epoch: [744/1000], Loss: 0.10833215713500977\n",
      "Epoch: [745/1000], Loss: 0.012973283417522907\n",
      "Epoch: [746/1000], Loss: 0.331400990486145\n",
      "Epoch: [747/1000], Loss: 0.13101936876773834\n",
      "Epoch: [748/1000], Loss: 0.0008587841293774545\n",
      "Epoch: [749/1000], Loss: 0.7685326337814331\n",
      "Epoch: [750/1000], Loss: 0.03263026848435402\n",
      "Epoch: [751/1000], Loss: 0.028958667069673538\n",
      "Epoch: [752/1000], Loss: 0.1818823367357254\n",
      "Epoch: [753/1000], Loss: 0.33859989047050476\n",
      "Epoch: [754/1000], Loss: 0.189199760556221\n",
      "Epoch: [755/1000], Loss: 0.00041750812670215964\n",
      "Epoch: [756/1000], Loss: 0.47546881437301636\n",
      "Epoch: [757/1000], Loss: 0.07718102633953094\n",
      "Epoch: [758/1000], Loss: 0.2147536277770996\n",
      "Epoch: [759/1000], Loss: 0.04161892831325531\n",
      "Epoch: [760/1000], Loss: 0.004728179425001144\n",
      "Epoch: [761/1000], Loss: 0.16958123445510864\n",
      "Epoch: [762/1000], Loss: 0.07188749313354492\n",
      "Epoch: [763/1000], Loss: 0.004185192286968231\n",
      "Epoch: [764/1000], Loss: 0.19428199529647827\n",
      "Epoch: [765/1000], Loss: 0.20662346482276917\n",
      "Epoch: [766/1000], Loss: 0.34809839725494385\n",
      "Epoch: [767/1000], Loss: 0.42466992139816284\n",
      "Epoch: [768/1000], Loss: 2.3433408737182617\n",
      "Epoch: [769/1000], Loss: 0.16109494864940643\n",
      "Epoch: [770/1000], Loss: 0.48212021589279175\n",
      "Epoch: [771/1000], Loss: 0.007815639488399029\n",
      "Epoch: [772/1000], Loss: 0.01203257404267788\n",
      "Epoch: [773/1000], Loss: 0.989878237247467\n",
      "Epoch: [774/1000], Loss: 0.20093655586242676\n",
      "Epoch: [775/1000], Loss: 0.25231820344924927\n",
      "Epoch: [776/1000], Loss: 0.06136765331029892\n",
      "Epoch: [777/1000], Loss: 0.9230856895446777\n",
      "Epoch: [778/1000], Loss: 1.0962822437286377\n",
      "Epoch: [779/1000], Loss: 0.11694400757551193\n",
      "Epoch: [780/1000], Loss: 0.060421302914619446\n",
      "Epoch: [781/1000], Loss: 0.637563943862915\n",
      "Epoch: [782/1000], Loss: 0.017458990216255188\n",
      "Epoch: [783/1000], Loss: 0.1067514643073082\n",
      "Epoch: [784/1000], Loss: 0.16200082004070282\n",
      "Epoch: [785/1000], Loss: 0.008663531392812729\n",
      "Epoch: [786/1000], Loss: 0.3585836887359619\n",
      "Epoch: [787/1000], Loss: 0.48555999994277954\n",
      "Epoch: [788/1000], Loss: 0.2461136430501938\n",
      "Epoch: [789/1000], Loss: 0.5821731090545654\n",
      "Epoch: [790/1000], Loss: 0.01435023732483387\n",
      "Epoch: [791/1000], Loss: 0.04903494194149971\n",
      "Epoch: [792/1000], Loss: 0.3789884150028229\n",
      "Epoch: [793/1000], Loss: 0.06281083077192307\n",
      "Epoch: [794/1000], Loss: 0.09048371016979218\n",
      "Epoch: [795/1000], Loss: 0.02826777659356594\n",
      "Epoch: [796/1000], Loss: 0.015082092955708504\n",
      "Epoch: [797/1000], Loss: 0.20468761026859283\n",
      "Epoch: [798/1000], Loss: 0.018389813601970673\n",
      "Epoch: [799/1000], Loss: 0.5358988642692566\n",
      "Epoch: [800/1000], Loss: 0.20590642094612122\n",
      "Epoch: [801/1000], Loss: 0.09930060803890228\n",
      "Epoch: [802/1000], Loss: 0.07654484361410141\n",
      "Epoch: [803/1000], Loss: 0.29513001441955566\n",
      "Epoch: [804/1000], Loss: 0.026251258328557014\n",
      "Epoch: [805/1000], Loss: 1.089505910873413\n",
      "Epoch: [806/1000], Loss: 0.34497711062431335\n",
      "Epoch: [807/1000], Loss: 0.19337990880012512\n",
      "Epoch: [808/1000], Loss: 0.506647527217865\n",
      "Epoch: [809/1000], Loss: 0.10057029128074646\n",
      "Epoch: [810/1000], Loss: 0.8948476314544678\n",
      "Epoch: [811/1000], Loss: 0.12957720458507538\n",
      "Epoch: [812/1000], Loss: 0.41659173369407654\n",
      "Epoch: [813/1000], Loss: 0.2675859332084656\n",
      "Epoch: [814/1000], Loss: 0.9793351292610168\n",
      "Epoch: [815/1000], Loss: 0.1467648148536682\n",
      "Epoch: [816/1000], Loss: 0.04718758910894394\n",
      "Epoch: [817/1000], Loss: 0.01700177974998951\n",
      "Epoch: [818/1000], Loss: 0.8997328281402588\n",
      "Epoch: [819/1000], Loss: 0.0002750307903625071\n",
      "Epoch: [820/1000], Loss: 1.277078628540039\n",
      "Epoch: [821/1000], Loss: 0.01631571352481842\n",
      "Epoch: [822/1000], Loss: 0.10076817125082016\n",
      "Epoch: [823/1000], Loss: 0.11919497698545456\n",
      "Epoch: [824/1000], Loss: 0.05853699520230293\n",
      "Epoch: [825/1000], Loss: 0.030350089073181152\n",
      "Epoch: [826/1000], Loss: 0.03516974300146103\n",
      "Epoch: [827/1000], Loss: 0.046271033585071564\n",
      "Epoch: [828/1000], Loss: 0.3863680958747864\n",
      "Epoch: [829/1000], Loss: 0.14112038910388947\n",
      "Epoch: [830/1000], Loss: 0.47269630432128906\n",
      "Epoch: [831/1000], Loss: 0.4314749836921692\n",
      "Epoch: [832/1000], Loss: 0.15546639263629913\n",
      "Epoch: [833/1000], Loss: 0.10132788866758347\n",
      "Epoch: [834/1000], Loss: 0.018938498571515083\n",
      "Epoch: [835/1000], Loss: 0.10605508089065552\n",
      "Epoch: [836/1000], Loss: 0.4976629316806793\n",
      "Epoch: [837/1000], Loss: 0.9085736870765686\n",
      "Epoch: [838/1000], Loss: 0.45949551463127136\n",
      "Epoch: [839/1000], Loss: 0.5768591165542603\n",
      "Epoch: [840/1000], Loss: 0.17686167359352112\n",
      "Epoch: [841/1000], Loss: 0.11223168671131134\n",
      "Epoch: [842/1000], Loss: 0.09220249950885773\n",
      "Epoch: [843/1000], Loss: 0.0006710314773954451\n",
      "Epoch: [844/1000], Loss: 0.5279505848884583\n",
      "Epoch: [845/1000], Loss: 0.20143885910511017\n",
      "Epoch: [846/1000], Loss: 0.62460857629776\n",
      "Epoch: [847/1000], Loss: 0.0004535793559625745\n",
      "Epoch: [848/1000], Loss: 0.5475355386734009\n",
      "Epoch: [849/1000], Loss: 0.09401088953018188\n",
      "Epoch: [850/1000], Loss: 0.00012062957102898508\n",
      "Epoch: [851/1000], Loss: 1.3767130374908447\n",
      "Epoch: [852/1000], Loss: 0.8510251641273499\n",
      "Epoch: [853/1000], Loss: 0.572721004486084\n",
      "Epoch: [854/1000], Loss: 0.10763925313949585\n",
      "Epoch: [855/1000], Loss: 0.344880610704422\n",
      "Epoch: [856/1000], Loss: 0.28424298763275146\n",
      "Epoch: [857/1000], Loss: 0.47288957238197327\n",
      "Epoch: [858/1000], Loss: 0.008830864913761616\n",
      "Epoch: [859/1000], Loss: 0.04804356396198273\n",
      "Epoch: [860/1000], Loss: 0.10588070750236511\n",
      "Epoch: [861/1000], Loss: 0.35482317209243774\n",
      "Epoch: [862/1000], Loss: 0.242611825466156\n",
      "Epoch: [863/1000], Loss: 0.4506189227104187\n",
      "Epoch: [864/1000], Loss: 0.47306424379348755\n",
      "Epoch: [865/1000], Loss: 0.22675132751464844\n",
      "Epoch: [866/1000], Loss: 0.4900050163269043\n",
      "Epoch: [867/1000], Loss: 0.023374466225504875\n",
      "Epoch: [868/1000], Loss: 0.24295130372047424\n",
      "Epoch: [869/1000], Loss: 0.07333600521087646\n",
      "Epoch: [870/1000], Loss: 0.7599120736122131\n",
      "Epoch: [871/1000], Loss: 0.019128547981381416\n",
      "Epoch: [872/1000], Loss: 0.0013759490102529526\n",
      "Epoch: [873/1000], Loss: 0.005770747549831867\n",
      "Epoch: [874/1000], Loss: 0.475022554397583\n",
      "Epoch: [875/1000], Loss: 0.415078341960907\n",
      "Epoch: [876/1000], Loss: 0.23725339770317078\n",
      "Epoch: [877/1000], Loss: 0.06241697445511818\n",
      "Epoch: [878/1000], Loss: 0.12361808866262436\n",
      "Epoch: [879/1000], Loss: 0.6195607781410217\n",
      "Epoch: [880/1000], Loss: 0.051843445748090744\n",
      "Epoch: [881/1000], Loss: 0.4972369074821472\n",
      "Epoch: [882/1000], Loss: 0.002737997565418482\n",
      "Epoch: [883/1000], Loss: 0.152852863073349\n",
      "Epoch: [884/1000], Loss: 0.4669002592563629\n",
      "Epoch: [885/1000], Loss: 1.8652318716049194\n",
      "Epoch: [886/1000], Loss: 0.011083891615271568\n",
      "Epoch: [887/1000], Loss: 0.005247711203992367\n",
      "Epoch: [888/1000], Loss: 0.001962058013305068\n",
      "Epoch: [889/1000], Loss: 0.11660155653953552\n",
      "Epoch: [890/1000], Loss: 0.5084380507469177\n",
      "Epoch: [891/1000], Loss: 0.8239023089408875\n",
      "Epoch: [892/1000], Loss: 0.0009823942091315985\n",
      "Epoch: [893/1000], Loss: 0.15119139850139618\n",
      "Epoch: [894/1000], Loss: 0.023920951411128044\n",
      "Epoch: [895/1000], Loss: 0.00287878280505538\n",
      "Epoch: [896/1000], Loss: 0.0009888276690617204\n",
      "Epoch: [897/1000], Loss: 0.47231829166412354\n",
      "Epoch: [898/1000], Loss: 0.8735519051551819\n",
      "Epoch: [899/1000], Loss: 0.12107484042644501\n",
      "Epoch: [900/1000], Loss: 0.013229859992861748\n",
      "Epoch: [901/1000], Loss: 0.5771390795707703\n",
      "Epoch: [902/1000], Loss: 0.685455322265625\n",
      "Epoch: [903/1000], Loss: 0.11244980990886688\n",
      "Epoch: [904/1000], Loss: 0.6133654117584229\n",
      "Epoch: [905/1000], Loss: 0.7722094058990479\n",
      "Epoch: [906/1000], Loss: 0.3363201320171356\n",
      "Epoch: [907/1000], Loss: 0.0003764221619348973\n",
      "Epoch: [908/1000], Loss: 0.5438998937606812\n",
      "Epoch: [909/1000], Loss: 0.022608231753110886\n",
      "Epoch: [910/1000], Loss: 0.08454874902963638\n",
      "Epoch: [911/1000], Loss: 0.02195325866341591\n",
      "Epoch: [912/1000], Loss: 0.46030494570732117\n",
      "Epoch: [913/1000], Loss: 0.02547939121723175\n",
      "Epoch: [914/1000], Loss: 0.06182148680090904\n",
      "Epoch: [915/1000], Loss: 0.011152384802699089\n",
      "Epoch: [916/1000], Loss: 0.027052821591496468\n",
      "Epoch: [917/1000], Loss: 0.0018892231164500117\n",
      "Epoch: [918/1000], Loss: 0.09430307149887085\n",
      "Epoch: [919/1000], Loss: 0.05503426119685173\n",
      "Epoch: [920/1000], Loss: 0.11544480174779892\n",
      "Epoch: [921/1000], Loss: 0.09853734076023102\n",
      "Epoch: [922/1000], Loss: 0.025242425501346588\n",
      "Epoch: [923/1000], Loss: 0.004756801761686802\n",
      "Epoch: [924/1000], Loss: 0.0673709288239479\n",
      "Epoch: [925/1000], Loss: 0.00013457657769322395\n",
      "Epoch: [926/1000], Loss: 0.1787966936826706\n",
      "Epoch: [927/1000], Loss: 0.09568803012371063\n",
      "Epoch: [928/1000], Loss: 0.1952868402004242\n",
      "Epoch: [929/1000], Loss: 0.09149988740682602\n",
      "Epoch: [930/1000], Loss: 0.0758432149887085\n",
      "Epoch: [931/1000], Loss: 0.6055871844291687\n",
      "Epoch: [932/1000], Loss: 0.9631603360176086\n",
      "Epoch: [933/1000], Loss: 0.15219402313232422\n",
      "Epoch: [934/1000], Loss: 0.4543285369873047\n",
      "Epoch: [935/1000], Loss: 0.10382629930973053\n",
      "Epoch: [936/1000], Loss: 0.12241444736719131\n",
      "Epoch: [937/1000], Loss: 0.1860845983028412\n",
      "Epoch: [938/1000], Loss: 0.16548456251621246\n",
      "Epoch: [939/1000], Loss: 0.2629992961883545\n",
      "Epoch: [940/1000], Loss: 0.06540822237730026\n",
      "Epoch: [941/1000], Loss: 0.45416632294654846\n",
      "Epoch: [942/1000], Loss: 0.021126259118318558\n",
      "Epoch: [943/1000], Loss: 0.23956221342086792\n",
      "Epoch: [944/1000], Loss: 0.13874229788780212\n",
      "Epoch: [945/1000], Loss: 0.6750422120094299\n",
      "Epoch: [946/1000], Loss: 0.5259068608283997\n",
      "Epoch: [947/1000], Loss: 0.17336183786392212\n",
      "Epoch: [948/1000], Loss: 0.007685028947889805\n",
      "Epoch: [949/1000], Loss: 0.011214900761842728\n",
      "Epoch: [950/1000], Loss: 0.003129220101982355\n",
      "Epoch: [951/1000], Loss: 0.007224666886031628\n",
      "Epoch: [952/1000], Loss: 1.169355034828186\n",
      "Epoch: [953/1000], Loss: 0.02309318818151951\n",
      "Epoch: [954/1000], Loss: 0.053879816085100174\n",
      "Epoch: [955/1000], Loss: 0.36945733428001404\n",
      "Epoch: [956/1000], Loss: 0.00043029230437241495\n",
      "Epoch: [957/1000], Loss: 0.06234581768512726\n",
      "Epoch: [958/1000], Loss: 0.12689879536628723\n",
      "Epoch: [959/1000], Loss: 0.35902148485183716\n",
      "Epoch: [960/1000], Loss: 0.15539802610874176\n",
      "Epoch: [961/1000], Loss: 0.272438108921051\n",
      "Epoch: [962/1000], Loss: 0.40570738911628723\n",
      "Epoch: [963/1000], Loss: 0.002929442096501589\n",
      "Epoch: [964/1000], Loss: 0.23602917790412903\n",
      "Epoch: [965/1000], Loss: 0.12438279390335083\n",
      "Epoch: [966/1000], Loss: 0.12547419965267181\n",
      "Epoch: [967/1000], Loss: 0.06991511583328247\n",
      "Epoch: [968/1000], Loss: 0.051329679787158966\n",
      "Epoch: [969/1000], Loss: 0.003826851723715663\n",
      "Epoch: [970/1000], Loss: 0.17586296796798706\n",
      "Epoch: [971/1000], Loss: 0.12176483869552612\n",
      "Epoch: [972/1000], Loss: 0.024954237043857574\n",
      "Epoch: [973/1000], Loss: 0.0241731945425272\n",
      "Epoch: [974/1000], Loss: 0.007169235497713089\n",
      "Epoch: [975/1000], Loss: 0.17292365431785583\n",
      "Epoch: [976/1000], Loss: 0.2814190983772278\n",
      "Epoch: [977/1000], Loss: 0.175764799118042\n",
      "Epoch: [978/1000], Loss: 0.46596115827560425\n",
      "Epoch: [979/1000], Loss: 0.060534920543432236\n",
      "Epoch: [980/1000], Loss: 0.14458364248275757\n",
      "Epoch: [981/1000], Loss: 0.9072049260139465\n",
      "Epoch: [982/1000], Loss: 0.015420615673065186\n",
      "Epoch: [983/1000], Loss: 0.026788627728819847\n",
      "Epoch: [984/1000], Loss: 0.11508157104253769\n",
      "Epoch: [985/1000], Loss: 0.11766153573989868\n",
      "Epoch: [986/1000], Loss: 0.14064045250415802\n",
      "Epoch: [987/1000], Loss: 0.6778361797332764\n",
      "Epoch: [988/1000], Loss: 0.053288061171770096\n",
      "Epoch: [989/1000], Loss: 0.03459976986050606\n",
      "Epoch: [990/1000], Loss: 0.021923288702964783\n",
      "Epoch: [991/1000], Loss: 0.08917495608329773\n",
      "Epoch: [992/1000], Loss: 0.7259225249290466\n",
      "Epoch: [993/1000], Loss: 0.007817582227289677\n",
      "Epoch: [994/1000], Loss: 0.24279850721359253\n",
      "Epoch: [995/1000], Loss: 0.02420356683433056\n",
      "Epoch: [996/1000], Loss: 0.015864141285419464\n",
      "Epoch: [997/1000], Loss: 0.005756324157118797\n",
      "Epoch: [998/1000], Loss: 0.0060817888006567955\n",
      "Epoch: [999/1000], Loss: 0.7614604234695435\n",
      "Epoch: [1000/1000], Loss: 0.3642290234565735\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch: [{epoch+1}/{epochs}], Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.74193548387096%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in dataloader_val:\n",
    "        outputs = model(inputs.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs, labels = next(iter(dataloader_val))\n",
    "# outputs = model(inputs.float())\n",
    "# _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "# fig, ax = plt.subplots(1, 4, figsize=(12, 3))\n",
    "# for i, axes in enumerate(ax):\n",
    "#     axes.imshow(inputs[i].view(2, 5))\n",
    "#     axes.set_title(f'Predicted: {predicted[i]}, Actual: {labels[i]}')\n",
    "#     axes.axis('off')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
