{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def evaluate(self, values):\n",
    "        pass\n",
    "    def to_scentence(self):\n",
    "        pass\n",
    "    def parse(text):\n",
    "        text = text.replace(' ', '')\n",
    "        if text[0] == '(' and text[-1] == ')':\n",
    "            text = text[1:-1]\n",
    "\n",
    "        if '(' not in text:\n",
    "            if '|' in text:\n",
    "                return Disjunction(Node.parse(text[:text.index('|')]), Node.parse(text[text.index('|') + 1:]))\n",
    "            elif '&' in text:\n",
    "                return Conjunction(Node.parse(text[:text.index('&')]), Node.parse(text[text.index('&') + 1:]))\n",
    "            elif '<->' in text:\n",
    "                return Biimplication(Node.parse(text[:text.index('<->')]), Node.parse(text[text.index('<->') + 3:]))\n",
    "            elif '->' in text:\n",
    "                return Implication(Node.parse(text[:text.index('->')]), Node.parse(text[text.index('->') + 2:]))\n",
    "            elif '!' in text:\n",
    "                return Negation(Node.parse(text[1:]))\n",
    "            return Variable(text, int(text[1:]))\n",
    "\n",
    "        depth = 0\n",
    "        for i in range(len(text)):\n",
    "            if text[i] == '(':\n",
    "                depth += 1\n",
    "            elif text[i] == ')':\n",
    "                depth -= 1\n",
    "            elif depth == 0 and text[i] == '|':\n",
    "                return Disjunction(Node.parse(text[:i]), Node.parse(text[i + 1:]))\n",
    "            elif depth == 0 and text[i] == '&':\n",
    "                return Conjunction(Node.parse(text[:i]), Node.parse(text[i + 1:]))\n",
    "            elif depth == 0 and text[i] == '-' and text[i + 1] == '>':\n",
    "                return Implication(Node.parse(text[:i]), Node.parse(text[i + 2:]))\n",
    "            elif depth == 0 and text[i] == '<' and text[i + 1] == '-' and text[i + 2] == '>':\n",
    "                return Biimplication(Node.parse(text[:i]), Node.parse(text[i + 3:]))\n",
    "            elif depth == 0 and text[i] == '!':\n",
    "                return Negation(Node.parse(text[i + 1:]))\n",
    "        \n",
    "        raise Exception('Something went wrong')\n",
    "    \n",
    "    def __str__(self):\n",
    "        pass\n",
    "\n",
    "class Variable(Node):\n",
    "    def __init__(self, name, index):\n",
    "        self.name = name\n",
    "        self.index = index\n",
    "\n",
    "    def evaluate(self, values):\n",
    "        return values[self.index]\n",
    "    \n",
    "    def to_scentence(self, root = True):\n",
    "        return f\"{self.name}{'.' if root else ''}\", 0\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Variable):\n",
    "            return self.name == other.name\n",
    "        if isinstance(other, Negation):\n",
    "            return self.name == other.expr.name\n",
    "        return False\n",
    "    \n",
    "class Negation(Node):\n",
    "    def __init__(self, expr):\n",
    "        self.expr = expr\n",
    "\n",
    "    def evaluate(self, values):\n",
    "        return not self.expr.evaluate(values)\n",
    "    \n",
    "    def to_scentence(self, root = True):\n",
    "        text, depth = self.expr.to_scentence(root = False)\n",
    "        return f\"!{text}{'.' if root else ''}\", depth\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"!{self.expr}\"\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Negation):\n",
    "            return self.expr == other.expr\n",
    "        if isinstance(other, Variable):\n",
    "            return self.expr.name == other.name\n",
    "        return False\n",
    "\n",
    "class Implication(Node):\n",
    "    def __init__(self, left, right):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def evaluate(self, values):\n",
    "        return not self.left.evaluate(values) or self.right.evaluate(values)\n",
    "    \n",
    "    def to_scentence(self, nested = False, root = True):\n",
    "        left_text, left_depth = self.left.to_scentence(nested=True, root=False) if isinstance(self.left, Implication) else self.left.to_scentence(root=False)\n",
    "        right_text, right_depth = self.right.to_scentence(root=False)\n",
    "\n",
    "        depth = max(left_depth, right_depth)\n",
    "\n",
    "        return f\"{'if ' if not nested else ''}{left_text} then{',' * depth} {right_text}{'.' if root else ''}\", depth + 1\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"({self.left} -> {self.right})\"\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Implication):\n",
    "            return self.left == other.left and self.right == other.right\n",
    "        return False\n",
    "    \n",
    "class Disjunction(Node):\n",
    "    def __init__(self, left, right):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def evaluate(self, values):\n",
    "        return self.left.evaluate(values) or self.right.evaluate(values)\n",
    "    \n",
    "    def to_scentence(self, root = True):\n",
    "        left_text, left_depth = self.left.to_scentence(root=False)\n",
    "        right_text, right_depth = self.right.to_scentence(root=False)\n",
    "        depth = max(left_depth, right_depth)\n",
    "        return f\"{left_text} or{',' * depth} {right_text}{'.' if root else ''}\", depth + 1\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"({self.left} | {self.right})\"\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Disjunction):\n",
    "            return self.left == other.left and self.right == other.right\n",
    "        return False\n",
    "    \n",
    "class Conjunction(Node):\n",
    "    def __init__(self, left, right):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def evaluate(self, values):\n",
    "        return self.left.evaluate(values) and self.right.evaluate(values)\n",
    "    \n",
    "    def to_scentence(self, root = True):\n",
    "        left_text, left_depth = self.left.to_scentence(root=False)\n",
    "        right_text, right_depth = self.right.to_scentence(root=False)\n",
    "        depth = max(left_depth, right_depth)\n",
    "        return f\"{left_text} and{',' * depth} {right_text}{'.' if root else ''}\", depth + 1\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"({self.left} & {self.right})\"\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Conjunction):\n",
    "            return self.left == other.left and self.right == other.right\n",
    "        return False\n",
    "    \n",
    "class Biimplication(Node):\n",
    "    def __init__(self, left, right):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def evaluate(self, values):\n",
    "        return self.left.evaluate(values) == self.right.evaluate(values)\n",
    "\n",
    "    def to_scentence(self, root = True):\n",
    "        left_text, left_depth = self.left.to_scentence(root=False)\n",
    "        right_text, right_depth = self.right.to_scentence(nested = True, root=False) if isinstance(self.right, Implication) else self.right.to_scentence(root=False)\n",
    "        depth = max(left_depth, right_depth)\n",
    "        return f\"{left_text} if and only if{',' * depth} {right_text}{'.' if root else ''}\", depth + 1\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"({self.left} <-> {self.right})\"\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Biimplication):\n",
    "            return self.left == other.left and self.right == other.right\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150580\n"
     ]
    }
   ],
   "source": [
    "def generate(depth, n):\n",
    "    for i in range(n):\n",
    "        yield Variable(f\"p{i}\", i)\n",
    "\n",
    "    if depth == 0:\n",
    "        for neg in generate(depth - 1, n):\n",
    "            yield Negation(neg)\n",
    "    elif depth > 0:\n",
    "        for left in generate(depth - 1, n):\n",
    "            for right in generate(depth - 1, n):\n",
    "                if left != right:\n",
    "                    yield Implication(left, right)\n",
    "                    yield Disjunction(left, right)\n",
    "                    yield Conjunction(left, right)\n",
    "                    yield Biimplication(left, right)\n",
    "\n",
    "print(len(list(generate(2, 4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Unique Truthtable Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_number(expression, n):\n",
    "    output = 0\n",
    "    for i in range(2 ** n):\n",
    "        values = [bool(i & (1 << j)) for j in range(n)]\n",
    "        if expression.evaluate(values):\n",
    "            output += 2 ** i\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(n, depth):\n",
    "    data = []\n",
    "    for expression in generate(depth, n):\n",
    "        number = generate_number(expression, n)\n",
    "        data.append([str(expression)] + [number])\n",
    "    output = pd.DataFrame(data, columns=[\"expression\", \"key\"])\n",
    "\n",
    "    for key in output['key'].unique():\n",
    "        output.loc[output['key'] == key, 'ratio'] = 1 / output.loc[output['key'] == key].shape[0]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# generate_dataset(4, 2).to_csv(\"dataset.csv\", index=False)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m test_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m test_data\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset.csv'"
     ]
    }
   ],
   "source": [
    "# generate_dataset(4, 2).to_csv(\"dataset.csv\", index=False)\n",
    "test_data = pd.read_csv(\"dataset.csv\")\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate premise from conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_premise(value, indexes):\n",
    "    for i in indexes:\n",
    "        if i < value: continue\n",
    "        for j in indexes:\n",
    "            if j < value: continue\n",
    "            if i != value and j != value and i > j and i & j == value:\n",
    "                yield i, j, value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((p3 -> !p2) & (!p1 & p3)) ('if p3 then !p2 and, !p1 and p3.', 2)\n",
      "((p3 -> !p2) & (!p1 & p3)) ('if p3 then !p2 and, !p1 and p3.', 2)\n"
     ]
    }
   ],
   "source": [
    "value = np.random.choice(list(generate(2,4)))\n",
    "\n",
    "print(value, value.to_scentence())\n",
    "parst = Node.parse(str(value))\n",
    "print(parst, parst.to_scentence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{if p0 or !p1 then, p3 and !p2. p1 and p2 if and only if, !p2 and !p3.} p2 if and only if, !p2 and !p3.\n"
     ]
    }
   ],
   "source": [
    "picked = test_data.sample(1)\n",
    "lists = list(generate_premise(picked[\"key\"].values[0], test_data[\"key\"].unique()))\n",
    "while len(lists) == 0:\n",
    "    picked = test_data.sample(1)\n",
    "    lists = list(generate_premise(picked[\"key\"].values[0], test_data[\"key\"].unique()))\n",
    "a,b,c = lists[np.random.randint(0, len(lists))]\n",
    "prem_0 = Node.parse(str(test_data[test_data[\"key\"] == a][\"expression\"].values[0])).to_scentence()\n",
    "prem_1 = Node.parse(str(test_data[test_data[\"key\"] == b][\"expression\"].values[0])).to_scentence()\n",
    "conc = Node.parse(str(test_data[test_data[\"key\"] == c][\"expression\"].values[0])).to_scentence()\n",
    "\n",
    "print(f'\\x7b{prem_0[0]} {prem_1[0]}\\x7d', f'{conc[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer():\n",
    "    symbols = ['{', '}', '.', ',', '!']\n",
    "    words = ['and', 'or', 'if', 'then', 'only']\n",
    "    def Split(input):\n",
    "        if input[0] in Tokenizer.symbols:\n",
    "            return [Tokenizer.symbols.index(input[0])] + Tokenizer.Split(input[1:])\n",
    "        elif input[-1] in Tokenizer.symbols:\n",
    "            return Tokenizer.Split(input[:-1]) + [Tokenizer.symbols.index(input[-1])]\n",
    "        elif input in Tokenizer.words:\n",
    "            return [Tokenizer.words.index(input) + len(Tokenizer.symbols)]\n",
    "        elif input[0] == 'p' and input[1:].isnumeric():\n",
    "            return [int(input[1:]) + len(Tokenizer.words) + len(Tokenizer.symbols)]\n",
    "        \n",
    "        raise Exception(f'Invalid input: {input}')\n",
    "    \n",
    "    def Tokenize(input):\n",
    "        output = []\n",
    "        input_words = input.split(' ')\n",
    "        for word in input_words:\n",
    "            if word in Tokenizer.symbols:\n",
    "                output.append(Tokenizer.symbols.index(word))\n",
    "            elif word in Tokenizer.words:\n",
    "                output.append(Tokenizer.words.index(word) + len(Tokenizer.symbols))\n",
    "            elif word[0] == 'p' and word[1:].isnumeric():\n",
    "                output.append(int(word[1:]) + len(Tokenizer.symbols) + len(Tokenizer.words))\n",
    "            else:\n",
    "                output += Tokenizer.Split(word)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 7, 10, 6, 4, 11, 8, 3, 13, 5, 4, 12, 2, 11, 5, 12, 7, 5, 9, 7, 3, 4, 12, 5, 4, 13, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "tokens = Tokenizer.Tokenize(f'\\x7b{prem_0[0]} {prem_1[0]}\\x7d')\n",
    "print(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
